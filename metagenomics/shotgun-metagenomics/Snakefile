# standard library imports
#
import os
import glob
import shutil

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)


RESULT_OUTDIR = 'out'


SPLIT_TABLE = srcdir("aux/split_table.sh")
# NOTE: needs pandas which is part of the metaphlan2 env!
MERGE_TABLES = srcdir("aux/merge_tables.py")


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")


include: "../../rules/logging.rules"
include: "../../rules/report.rules"


rule final:
    input:
        "report.html",
        expand(os.path.join(RESULT_OUTDIR, "tax_profile.SUCCESS")),
        expand(os.path.join(RESULT_OUTDIR, "pathway_profile.SUCCESS")),
        expand(os.path.join(RESULT_OUTDIR, "{sample}/reads/all-trimmed_1_fastqc.html"),
            sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR, "{sample}/reads/all-trimmed-decont_1_fastqc.html"),
            sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR,"{sample}/srst2/srst2.SUCCESS"),
                    sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR,"{sample}/reads/counts.txt"),
                    sample=config['samples']),


rule read_trimming:
    # adopted from vipr
    input:
        fq1 = lambda wc: config['readunits'][wc.unit]['fq1'],
        fq2 = lambda wc: config['readunits'][wc.unit]['fq2'],
    output:
        fq1 = "{prefix}/{sample}/reads/{unit}-trimmed-pair1.fastq.gz",
        fq2 = "{prefix}/{sample}/reads/{unit}-trimmed-pair2.fastq.gz"
    log:
        "{prefix}/{sample}/reads/{unit}-trimmed.log"
    message:
        "Trimming and filtering input reads for unit {wildcards.unit} of sample {wildcards.sample}"
    threads:
        4
    #conda:
    params:
        endqual = 3,
        minlen = 30,
        filter_many_ns_arg = "-n",
    shell:
        # skewer cannot read from stream so needs to be run per pair
        "{{ "
        "outprefix=$(echo {output.fq1} | sed -e 's,-trimmed-pair1.fastq.gz,,');"
        "skewer --quiet -t {threads} -m pe -n -q {params.endqual} {params.filter_many_ns_arg}"
        " -l {params.minlen} -z -o $outprefix {input.fq1} {input.fq2};"
        " }} >& {log}"


localrules: combine_trim
rule combine_trim:
    # adopted from vipr
    input:
        # this looks rather clumsy but somehow works, i.e. returns a list
        fq1 = lambda wc: ["{prefix}/{sample}/reads/{unit}-trimmed-pair1.fastq.gz".format(
            prefix=wc.prefix, sample=wc.sample, unit=ru) for ru in config['samples'][wc.sample]],
        fq2 = lambda wc: ["{prefix}/{sample}/reads/{unit}-trimmed-pair2.fastq.gz".format(
            prefix=wc.prefix, sample=wc.sample, unit=ru) for ru in config['samples'][wc.sample]],
    output:
        fq1 = "{prefix}/{sample}/reads/all-trimmed_1.fastq.gz",
        fq2 = "{prefix}/{sample}/reads/all-trimmed_2.fastq.gz"
    log:
        "{prefix}/{sample}/reads/all-trimmed.log"
    message:
        "Combining units for sample {wildcards.sample}"
    threads:
        1
    #conda:
    #params:
    run:
        assert len(input.fq1) == len(input.fq2)
        if len(input.fq1) > 1:
            shell("{{ zcat {input.fq1} | gzip > {output.fq1}; zcat {input.fq2} | gzip > {output.fq2}; }} >& {log};")
        else:
            ifq1rel = os.path.relpath(str(input.fq1), os.path.dirname(str(output.fq1)))
            ifq2rel = os.path.relpath(str(input.fq2), os.path.dirname(str(output.fq2)))
            shell("{{ ln -sf {ifq1rel} {output.fq1} && touch -h {output.fq1};"
                  " ln -sf {ifq2rel} {output.fq2} && touch -h {output.fq2}; }} >& {log};")
            # for touch, see https://bitbucket.org/snakemake/snakemake/issues/397/unable-to-set-utime-on-symlink-your-python


rule decont:
    input:
        fq1 = "{prefix}_1.fastq.gz",
        fq2 = "{prefix}_2.fastq.gz",
        decont_genome = config['references']['decont_genome'],
        decont_genome_idx = config['references']['decont_genome'] + ".pac",
    output:
        fq1 = "{prefix}-decont_1.fastq.gz",
        fq2 = "{prefix}-decont_2.fastq.gz",
        bam = "{prefix}-decont.bam",
        log = "{prefix}-decont.log"# needed for later processing and hence not under log directive
    message:
        "Decontaminating reads"
    threads:
        4
    params:
        outprefix = lambda wc: "{}-decont".format(wc.prefix),
        mincov = 0.50
    shell:
        "decont.py -i {input.fq1} {input.fq2} -t {threads} -c {params.mincov}"
        " -r {input.decont_genome} -o {params.outprefix} >& {output.log};"


rule fastqc:
    input:
        '{prefix}.fastq.gz'
    output:
        '{prefix}_fastqc.zip',
        '{prefix}_fastqc.html'
    log:
        '{prefix}_fastqc.log'
    threads:
        2
    message:
        "Running fastqc on {input}"
    shell:
        "fastqc -t {threads} {input}"

        
localrules: fake_gunzip_single_end
rule fake_gunzip_single_end:
    input:
        fq1 = "{prefix}_1.fastq.gz",
        fq2 = "{prefix}_2.fastq.gz",
    output:
        temp("{prefix}_SR.fastq",)
    message:
        "Creating fake, unzipped SR"
    log:
        temp("{prefix}_SR.fastq.log",)
    shell:
        "gzip -dc {input} >{output} 2>{log}"


rule srst2:
    input:
        fq1 = "{prefix}/{sample}/reads/all-trimmed-decont_1.fastq.gz",
        fq2 = "{prefix}/{sample}/reads/all-trimmed-decont_2.fastq.gz",
        db = "/mnt/projects/bertrandd/opera_lg/CRE/DATABASE/srst2/data/ARGannot.r1.fasta"
    output:
        fg = "{prefix}/{sample}/srst2/{sample}__fullgenes__ARGannot.r1__results.txt",
        g = "{prefix}/{sample}/srst2/{sample}__genes__ARGannot.r1__results.txt",
        pu = temp("{prefix}/{sample}/srst2/{sample}__all-trimmed-decont.ARGannot.r1.pileup"),
        bf = "{prefix}/{sample}/srst2/{sample}__all-trimmed-decont.ARGannot.r1.sorted.bam",
        flag = touch("{prefix}/{sample}/srst2/srst2.SUCCESS")
    message:
        "Running SRST2 (in it's own environment)"
    #conda:
    #    "envs/srst2-0.2.0.yaml"
    params:
        mincov = 90,
    threads:
        4
    log:
        "{prefix}/{sample}/srst2/srst2.log"
    shell:
        "module load srst2/0.2.0;"
        "srst2 --input_pe {input.fq1} {input.fq2} --output $(dirname {output.fg})/{wildcards.sample}"
        " --log --gene_db {input.db} --read_type q --forward _1 --reverse _2 --threads 4"
        " --min_coverage {params.mincov} >& {log}"


localrules: countreads
rule countreads:
    input:
        decont_log = "{prefix}/{sample}/reads/all-trimmed-decont.log",
        fq1 = "{prefix}/{sample}/reads/all-trimmed_1.fastq.gz",
        fq2 = "{prefix}/{sample}/reads/all-trimmed_2.fastq.gz",
        fastqczip = "{prefix}/{sample}/reads/all-trimmed_1_fastqc.zip",
    output:
        cr = "{prefix}/{sample}/reads/counts.txt",
    message:
        "Counting reads"
    log:
        "{prefix}/{sample}/reads/countreads.log"
    shell:
        " {{"
        " echo -e 'sample\tnum-read-pairs-after-trimming\tnum-read-pairs-after-decont' > {output.cr};"
        " numreads=$(unzip -p {input.fastqczip} '*/fastqc_data.txt' | awk '/Total Sequences/ {{print $NF}}');"
        " numreadsdecont=$(awk '/Reads written.*fastq/ {{print $NF; exit}}' {input.decont_log});"
        " echo -e \"{wildcards.sample}\t$numreads\t$numreadsdecont\" >> {output.cr};"
        " }} >& {log}"


rule kraken:
    input:
        fq1 = "{prefix}/{sample}/reads/all-trimmed-decont_1.fastq.gz",
        fq2 = "{prefix}/{sample}/reads/all-trimmed-decont_2.fastq.gz",
        db = config['references']['kraken_db']
    output:
        tsv = "{prefix}/{sample}/kraken_profile/kraken.tsv",
        mpa = "{prefix}/{sample}/kraken/kraken.mpa.gz",
        out = "{prefix}/{sample}/kraken/kraken.out.gz"
    log:
        "{prefix}/{sample}/kraken/kraken.log"
    message:
        "Running Kraken on {wildcards.sample}"
    threads:
        8
    shell:
        "{{"
        " mparaw=$(echo {output.mpa} | sed -e 's,.gz,,');"
        " outraw=$(echo {output.out} | sed -e 's,.gz,,');"
        " kraken  --preload --db {input.db} --paired"
        " --threads {threads} {input.fq1} {input.fq2} > $outraw;"
        " kraken-translate --db {input.db} --mpa-format $outraw > $mparaw;"
        " kraken-mpa-report --db {input.db} $outraw > {output.tsv};"
        " gzip $mparaw $outraw;"
        " }} >& {log};"


rule metaphlan2:
    input:
        fq = "{prefix}/{sample}/reads/all-trimmed-decont_SR.fastq",
        pkl = config['references']['metaphlan2_pkl']
    output:
        tsv = "{prefix}/{sample}/metaphlan2_profile/metaphlan2.tsv",
        # intermediate BowTie2 output for re-running quickly
        bowtie = "{prefix}/{sample}/metaphlan2_profile/metaphlan2.bowtie.bz2",
        sam = "{prefix}/{sample}/metaphlan2_profile/metaphlan2.sam.bz2"
    log:
         "{prefix}/{sample}/metaphlan2_profile/metaphlan2.log"
    message:
        "Running Metaphlan on {wildcards.sample}"
    threads:
        8
    shell:
        "metaphlan2.py {input.fq} --input_type fastq --mpa_pkl {input.pkl}"
        " --bowtie2db {config[references][metaphlan2_db]} --bowtie2out {output.bowtie} -s {output.sam} "
        " --nproc {threads} >{output.tsv} 2>{log};"


rule humann2:
    input:
        fq = "{prefix}/{sample}/reads/all-trimmed-decont_SR.fastq",
        nucl_db = config['references']['humann2_nucleotide'],
        prot_db = config['references']['humann2_protein'],
        pkl = config['references']['metaphlan2_pkl']
    output:
        gf = "{prefix}/{sample}/humann2/{sample}_genefamilies.tsv",
        gfn = "{prefix}/{sample}/humann2/{sample}_genefamilies.relab.tsv",
        pw = "{prefix}/{sample}/humann2/{sample}_pathabundance.tsv",
        pwn = "{prefix}/{sample}/humann2/{sample}_pathabundance.relab.tsv",
        cov = "{prefix}/{sample}/humann2/{sample}_pathcoverage.tsv",
        flag = "{prefix}/{sample}/humann2/humann2.SUCCESS"
    message:
        "Running HUMAnN2 on {wildcards.sample}"
    log:
        "{prefix}/{sample}/humann2/humann2.log"
    threads:
        8
    # rerunning metaphlan instead of reusing. chenhao says necessary because metaphlan itself is optional
    shell:
        "{{ "
        "humann2 -i {input.fq}"
        " -o $(dirname {output.gf}) "
        #" --metaphlan {METAPHLAN2_PATH} "
        #" --diamond {DIAMOND_PATH}"
        #" --input-format fastq.multi"
        " --metaphlan-options=' --mpa_pkl {input.pkl} --bowtie2db {config[references][metaphlan2_db]}'"
        " --output-basename $(basename {output.gf} | sed -e 's,_genefamilies.tsv,,')"
        " --remove-temp-output"
        " --nucleotide-database {input.nucl_db}"
        " --protein-database {input.prot_db}"
        " --threads {threads};"
        "echo 'INFO: humann2 completed';"
        "humann2_renorm_table --input {output.gf}"
        " --output {output.gfn}"
        " --units relab;"
        "echo 'INFO: humann2_renorm_table genefamilies completed';"
        "humann2_renorm_table --input {output.pw}"
        " --output {output.pwn}"
        " --units relab;"
        "echo 'INFO: humann2_renorm_table pathabundance completed';"
        "touch {output.flag};"
        " }} >& {log}"


localrules: merge_humann2
rule merge_humann2:
    input:
        gfns = expand("{{prefix}}/{sample}/humann2/{sample}_genefamilies.relab.tsv",
                      sample=config['samples']),
        pwns = expand("{{prefix}}/{sample}/humann2/{sample}_pathabundance.relab.tsv",
                      sample=config['samples']),
        covs = expand("{{prefix}}/{sample}/humann2/{sample}_pathcoverage.tsv",
                      sample=config['samples']),
    output:
        gf = "{prefix}/merged_table_humann2/genefamily.tsv",
        pw = "{prefix}/merged_table_humann2/pathabundance.tsv",
        cov = "{prefix}/merged_table_humann2/pathcoverage.tsv",
        flag = "{prefix}/pathway_profile.SUCCESS"
    message:
        "Merging HUMAnN2 results for all samples"
    threads:
        1
    run:
        # need all input files to be in one folder, so symlink
        for in_files, out_file, pattern in zip([input.gfns, input.pwns, input.covs],
                                               [output.gf, output.pw, output.cov],
                                               ["genefamilies.relab", "pathabundance.relab" , "pathcoverage"]):
            tmp_indir = out_file + ".tmp"
            if os.path.exists(tmp_indir):
                shutil.rmtree(tmp_indir)
            os.mkdir(tmp_indir)
            for f in in_files:
                os.symlink(os.path.abspath(f),
                           os.path.join(tmp_indir, os.path.basename(f)))

            cmd = "humann2_join_tables --input {} --output {} --file_name {};".format(
                tmp_indir, out_file, pattern)
            shell(cmd)

            shutil.rmtree(tmp_indir)

        shell("touch {output.flag};")


localrules: split_tables
rule split_tables:
    input:
        "{prefix}/{sample}/{method}_profile/{method}.tsv"
    output:
        touch("{prefix}/split_table_{method}/{sample}.SUCCESS")
    log:
        "{prefix}/split_table_{method}/{sample}.log"
    message:
        "Splitting tables for {wildcards.method} on {wildcards.sample}"
    threads:
        1
    shell:
        "{{"
        " outpref=$(echo {output} | sed -e 's,.SUCCESS,,');"
        " {SPLIT_TABLE} {input} $outpref;"
        " }} >& {log}"


rule merge_tables:
    input:
        expand("{{prefix}}/split_table_{method}/{sample}.SUCCESS",
               method=config['profilers'], sample=config['samples'])
    output:
        touch("{prefix}/tax_profile.SUCCESS")
    message:
        "Merging tables"
    threads:
        1
    run:
        for m in config['profilers']:
            IDS = glob.glob(os.path.join(
                RESULT_OUTDIR, "split_table_{}".format(m), "*.table.?"))
            tax = set([x.split(".")[-1] for x in IDS])
            output_dir = os.path.join(
                RESULT_OUTDIR, "merged_table_{}".format(m))
            if not os.path.exists(output_dir):
                os.mkdir(output_dir)
            for t in tax:
                cmd = "{MERGE_TABLES} -p '[A-Z]+[0-9]+'"
                cmd += " {}/split_table_{}/*table.{}".format(RESULT_OUTDIR, m, t)
                cmd += " -o {}/{}.{}.profile_merged.tsv".format(output_dir, t, m)
                shell(cmd)
