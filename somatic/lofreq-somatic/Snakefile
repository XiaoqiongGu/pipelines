# standard library imports
#
import os

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit, get_sample_for_unit


RESULT_OUTDIR = 'out'


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")


include: "../../rules/snpeff.rules"
include: "../../rules/logging.rules"
include: "../../rules/samtools.rules"
include: "../../rules/sambamba.rules"
include: "../../rules/vcf.rules"
include: "../../rules/report.rules"
include: "lofreq.rules"
include: "lacer.rules"


localrules: final, report, intervals_wo_excl


assert sorted(config['samples']) == sorted(["normal", "tumor"])


NORMAL_DIR = os.path.join(RESULT_OUTDIR, 'normal')
TUMOR_DIR = os.path.join(RESULT_OUTDIR, 'tumor')
VARIANTS_DIR = os.path.join(RESULT_OUTDIR, 'variants')

        
rule final:
    input:
        os.path.join(VARIANTS_DIR, 'lofreq_somatic_final_minus-dbsnp.snvs.snpeff.vcf.gz.tbi'),
        os.path.join(VARIANTS_DIR, 'lofreq_somatic_final_minus-dbsnp.indels.snpeff.vcf.gz.tbi'),
        "report.html"


# FIXME unused
#MAXDEPTH = {'targeted': 100000,
#             'WES': 10000,
#             'WGS': 1000}


bam_suffix = '.bwamem.lofreq'
if config['mark_dups']:
    bam_suffix += '.dedup'
bam_suffix += ".lacer"
rule lofreq_somatic:
    input:
        nbam = os.path.join(NORMAL_DIR, 'normal' + bam_suffix + '.bam'),
        nbai = os.path.join(NORMAL_DIR, 'normal' + bam_suffix + '.bam.bai'),
        tbam = os.path.join(TUMOR_DIR, 'tumor' + bam_suffix + '.bam'),
        tbai = os.path.join(TUMOR_DIR, 'tumor' + bam_suffix + '.bam.bai'),
        bed = os.path.join(RESULT_OUTDIR, "interval_wo_excl.bed"),
        reffa = config['references']['genome'],
        refidx = config['references']['genome'] + ".fai",
        dbsnp = config['references']['dbsnp']
    output:
        rlx_vars = expand(os.path.join(VARIANTS_DIR, 'lofreq_{sample}_relaxed.vcf.gz'),
                             sample=['normal', 'tumor']),
        rlx_logs = expand(os.path.join(VARIANTS_DIR, 'lofreq_{sample}_relaxed.log'),
                             sample=['normal', 'tumor']),
        stringent_vars = expand(os.path.join(VARIANTS_DIR, 'lofreq_{sample}_stringent.{vartype}.vcf.gz'),
                                sample=['normal', 'tumor'], vartype=['snvs', 'indels']),
        raw_vars = expand(os.path.join(VARIANTS_DIR, 'lofreq_somatic_raw.{vartype}.vcf.gz'),
                          vartype=['snvs', 'indels']),
        final_vars = expand(os.path.join(VARIANTS_DIR, 'lofreq_somatic_final{dbsnp}.{vartype}.vcf.gz'),
                            dbsnp=['', '_minus-dbsnp'], vartype=['snvs', 'indels']),
    log:
        os.path.join(VARIANTS_DIR, 'lofreq_somatic.log')
    benchmark:
        os.path.join(VARIANTS_DIR, 'lofreq_somatic.benchmark.log')
    message:
        "Calling somatic variants with LoFreq"
    threads:
        16
    #params:
    #    #maxdepth = MAXDEPTH[config['seqtype']],
    shell:
        "lofreq somatic -n {input.nbam} -t {input.tbam} -f {input.reffa}"
                            " -o $(echo {output.final_vars[0]} | sed -e 's,somatic_final.*,,')"
        " -l {input.bed} -d {input.dbsnp} --threads {threads} --call-indels >& {log}"

        

# for somatic: sample is normal or tumor
rule unit_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        lambda wildcards: expand("{prefix}/unit-{unit}.bwamem.merged.lofreq.bam",
                                 prefix=wildcards.prefix,
                                 unit=config['samples'][wildcards.sample])
    output:
        temp('{prefix}/{sample}/{sample}.bwamem.lofreq.bam')
    log:
        '{prefix}/{sample}/{sample}.bwamem.lofreq.bam.unit_merge.log'
    benchmark:
        '{prefix}/{sample}/{sample}.bwamem.lofreq.bam.unit_merge.benchmark.log'
    message:
        "Merging units to {output}"
    threads:
        4
    run:
        # readgroup and pg now different, so make PG and RG uniq (default)
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log}; sleep 30;")


rule split_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        bams = expand('{{prefix}}.chrsplit.{ctr}.lofreq.bam',
                      ctr=range(config["references"]["num_chroms"]+1))
        # +1 for unaligned reads
    output:
        bam = temp('{prefix}.merged.lofreq.bam')
    log:
        '{prefix}.merged.lofreq.bam.split_merge.log'
    benchmark:
        '{prefix}.merged.lofreq.bam.split_merge.benchmark.log'
    message:
        "Merging chr-splits"
    threads:
        4
    run:
        if len(input) > 1:
            # same readgroup and pg, so combine colliding PG and RG
            shell("samtools merge -c -p -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log}; sleep 30;")


# WARN: Near identical copy from BWA-MEM
# - replaced sorted with split_bam_by_chr and changed out accordingly
# - removed fixmate (no points since we run viterbi later)
# - increased threads (since we don't sort etc.)
rule map_split:
    """
    - Setting read groups correctly is tricky and also depends on downstream programs. 
      See e.g. http://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups
      For example for BQSR PU takes precedence over ID. PU should contain lane.
    - More threads mean more memory because of sorting
    - This originated from the equally named SG10K rule
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: fastqs_from_unit(config["readunits"][wildcards.unit])
    output:
        bams=temp(expand('{{prefix}}/unit-{{unit}}.bwamem.chrsplit.{ctr}.bam',
                         ctr=range(config["references"]["num_chroms"]+1)))
                         # +1 for unaligned reads
    log:
        '{prefix}/unit-{unit}.bwamem.map.log'
    benchmark:
        '{prefix}/unit-{unit}.bwamem.map_split.benchmark.log'
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        center = config.get("center", "GIS"),
        platform = config.get("platform", "Illumina"),
        rg_id=lambda wildcards: config["readunits"][wildcards.unit]['rg_id'],# always set
        lib_id=lambda wildcards: gen_rg_lib_id(config["readunits"][wildcards.unit]),
        pu_id=lambda wildcards: gen_rg_pu_id(config["readunits"][wildcards.unit]),
        #outprefix=lambda wildcards: get_outprefix_for_map_mdups_split(wildcards),
        outprefix=lambda wildcards: '{}/unit-{}.bwamem.chrsplit'.format(wildcards.prefix, wildcards.unit),# keep in sync with input
        sample=lambda wildcards: get_sample_for_unit(wildcards.unit, config)
    message:
        'Aligning, marking duplicates (if set) and splitting per chrom'
    threads:
        # see also BWA-MEM
        16
    shell:
        "{{ bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\\tID:{params.rg_id}\\tPL:{params.platform}\\tPU:{params.pu_id}\\tLB:{params.lib_id}\\tSM:{params.sample}\\tCN:{params.center}'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        " split_bam_by_chr -S -l 0 -o {params.outprefix} -; }} >& {log}"
