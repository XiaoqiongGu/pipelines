# standard library imports
#
import os
import subprocess
import shutil

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit, get_sample_for_unit
from pipelines import chroms_and_lens_from_from_fasta


RESULT_OUTDIR = './out'


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")

# gatk_mapping needs these
NORMAL_DIR = os.path.join(RESULT_OUTDIR, 'normal')
TUMOR_DIR = os.path.join(RESULT_OUTDIR, 'tumor')
VARIANTS_DIR = os.path.join(RESULT_OUTDIR, 'variants')


include: "../../rules/samtools.rules"
include: "../../rules/logging.rules"
include: "bwa_mem.rules"
include: "gatk_mapping.rules"


if config['seqtype'] == 'targeted':
    localrules: final, report, mutect_combine, prep_bed_files, gatk_recalibrate_bam gatk_recalibrate_info
else:    
    localrules: final, report, mutect_combine, prep_bed_files


assert sorted(config['samples']) == sorted(["normal", "tumor"])


rule final:
    input:
        expand(os.path.join(VARIANTS_DIR, 'mutect.{ext}'), ext=['vcf', 'txt']),
        report="report.html"


rule report:
    input:
        expand(os.path.join(VARIANTS_DIR, 'mutect.{ext}'), ext=['vcf', 'txt']),
    output:
        html="report.html"
    params:
        samplenames=', '.join(config['samples'].keys())
    run:
        workflow_home = os.path.dirname(os.path.realpath(workflow.snakefile))
        readme = "EMPTY"
        with open(os.path.join(workflow_home, "README.rst")) as fh:
            readme = fh.read()
            
        report("""
=================================================================
Pipeline {config[ELM][pipeline_name]} run on {params.samplenames}
=================================================================

Version Info
------------

{config[ELM][pipeline_version]} 

""" + readme, output.html, metadata="Research Pipeline Development Team (rpd@gis.a-star.edu.sg)",# **input)
               conf="conf.yaml")
        # from doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch to have at least something


rule prep_bed_files:
    """Prepare bed files to be able to run haplotype caller per chromosome
    to speed things up. if we also have a global bed file intersect
    with this one.

    NOTE: this might produce empty bed files!

    """
    input:
        ref = config['references']['genome'],
        reffai = config['references']['genome'] + ".fai"
    output:
        bed = temp(expand(os.path.join(RESULT_OUTDIR, "chr.split.{ctr}.bed"),
                          ctr=range(config["references"]["num_chroms"])))
    log:
        os.path.join(RESULT_OUTDIR, "chr.split.log")
    params:
        outbedfmt = os.path.join(RESULT_OUTDIR, "chr.split.{}.bed")
    message:
        "Preparing intervals for splitting jobs"
    run:
        for (i, (s, l)) in enumerate(chroms_and_lens_from_from_fasta(input.ref)):
            outbed = params.outbedfmt.format(i)
            tmpbed = outbed + ".tmp"
            # write one bed per chrom
            with open(tmpbed, 'w') as fh:
                if s not in config['references'].get('excl_chrom', []):
                    fh.write("{}\t0\t{}\n".format(s, l))
                # else: empty file
                
            # intersect with given bed if needed
            # NOTE: might produce empty files (which is what we want)
            # Can also deal with empty import (create above if in excl)
            if config['intervals']:
                shell("bedtools intersect -a {} -b {} > {} 2> {{log}}".format(
                    config['intervals'], tmpbed, outbed))
                os.unlink(tmpbed)
            else:
                shutil.move(tmpbed, outbed)

rule unit_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        lambda wildcards: expand("{prefix}/{sample}/unit-{unit}.bwamem.bam",
                                 prefix=wildcards.prefix,
                                 sample=wildcards.sample,
                                 unit=config['samples'][wildcards.sample])
    output:
        temp('{prefix}/{sample}/{sample}.bwamem.bam')
    log:
        '{prefix}/{sample}/{sample}.log'
    message:
        "Merging units to {output}"
    threads:
        8
    run:
        # readgroup and pg now different, so make PG and RG uniq (default)
        # not running mark_dups_pipe_cmd again since not read name sorted anymore
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log};")
               

rule mutect_per_region:
    input:
        nbam = os.path.join(NORMAL_DIR, 'normal.bwamem.realn.recal.bam'),
        nbai = os.path.join(NORMAL_DIR, 'normal.bwamem.realn.recal.bam.bai'),
        tbam = os.path.join(TUMOR_DIR, 'tumor.bwamem.realn.recal.bam'),
        tbai = os.path.join(TUMOR_DIR, 'tumor.bwamem.realn.recal.bam.bai'),
        # FIXME bed = os.path.join(RESULT_OUTDIR, "interval_wo_excl.bed"),
        reffa = config['references']['genome'],
        refidx = config['references']['genome'] + ".fai",
        dbsnp = config['references']['dbsnp'],
        cosmic = config['references']['cosmic'],
        bed = os.path.join(RESULT_OUTDIR, "chr.split.{ctr}.bed") # see prep_bed_files
    output:
        vcf = temp("{prefix}/mutect.{ctr}.vcf"),
        out = temp("{prefix}/mutect.{ctr}.txt"),
        cov = temp("{prefix}/mutect.{ctr}.wig")
    log:
        os.path.join(VARIANTS_DIR, 'mutect.log')
    message:
        "Calling somatic variants with MuTect"
    params:
        frac_cont_arg = "--fraction_contamination {}".format(config["frac_cont"]) if config.get("frac_cont") else ""
    threads:
        1
    shell:
        # https://www.broadinstitute.org/cancer/cga/mutect_run
        #  --enable_extended_output
        'MUTECT_THREADS={threads} MUTECT_MEM=8g mutect_wrapper'
        ' --reference_sequence {input.reffa}'
        ' -I:normal {input.nbam} -I:tumor {input.tbam}'
        ' {params.frac_cont_arg}'
        ' --dbsnp {input.dbsnp} --cosmic {input.cosmic}'
        ' --intervals {input.bed}'
        ' --coverage_file {output.cov}'
        ' --out {output.out} --vcf {output.vcf}'
        ' >& {log}'

rule mutect_combine:
    input:
        vcf = expand("{{prefix}}/mutect.{ctr}.vcf", ctr=range(config["references"]["num_chroms"])),
        out = expand("{{prefix}}/mutect.{ctr}.txt", ctr=range(config["references"]["num_chroms"])),
        cov = expand("{{prefix}}/mutect.{ctr}.wig", ctr=range(config["references"]["num_chroms"])),
    output:
        vcf = "{prefix}/mutect.vcf",
        out = "{prefix}/mutect.txt",
        cov = "{prefix}/mutect.wig",
    log:
        os.path.join(VARIANTS_DIR, "mutect_combine.log")
    message:
        "Combining results"
    threads:
        1
    shell:
        "{{ cat {input.vcf} > {output.vcf};"
        " cat {input.out} > {output.out}; "
        " cat {input.cov} > {output.cov}; }} >& {log}"
    
