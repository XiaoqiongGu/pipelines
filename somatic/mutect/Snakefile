# standard library imports
#
import os
import subprocess
import shutil

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit, get_sample_for_unit
from pipelines import chroms_and_lens_from_from_fasta


RESULT_OUTDIR = 'out'


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")

# gatk_mapping needs these
NORMAL_DIR = os.path.join(RESULT_OUTDIR, 'normal')
TUMOR_DIR = os.path.join(RESULT_OUTDIR, 'tumor')
VARIANTS_DIR = os.path.join(RESULT_OUTDIR, 'variants')


include: "../../rules/samtools.rules"
include: "../../rules/logging.rules"
include: "../../rules/report.rules"
include: "../../rules/vcf.rules"
include: "../../rules/sambamba.rules"
include: "bwa_mem.rules"
include: "gatk_mapping.rules"


if config['seqtype'] == 'targeted':
    localrules: final, report, mutect_pass, mutect_combine, prep_bed_files, gatk_recalibrate_bam gatk_recalibrate_info
else:    
    localrules: final, report, mutect_pass, mutect_combine, prep_bed_files


assert sorted(config['samples']) == sorted(["normal", "tumor"])


rule final:
    input:
        os.path.join(VARIANTS_DIR, 'mutect.PASS.vcf.gz.tbi'),
        "report.html"



rule prep_bed_files:
    """Prepare bed files to be able to run haplotype caller per chromosome
    to speed things up. if we also have a global bed file intersect
    with this one.

    NOTE: this might produce empty bed files!

    """
    input:
        ref = config['references']['genome'],
        reffai = config['references']['genome'] + ".fai"
    output:
        bed = temp(expand(os.path.join(RESULT_OUTDIR, "chr.split.{ctr}.bed"),
                          ctr=range(config["references"]["num_chroms"])))
    log:
        os.path.join(RESULT_OUTDIR, "chr.split.log")
    params:
        outbedfmt = os.path.join(RESULT_OUTDIR, "chr.split.{}.bed")
    message:
        "Preparing intervals for splitting jobs"
    run:
        for (i, (s, l)) in enumerate(chroms_and_lens_from_from_fasta(input.ref)):
            outbed = params.outbedfmt.format(i)
            tmpbed = outbed + ".tmp"
            # write one bed per chrom
            with open(tmpbed, 'w') as fh:
                if s not in config['references'].get('excl_chrom', []):
                    fh.write("{}\t0\t{}\n".format(s, l))
                # else: empty file
                
            # intersect with given bed if needed
            # NOTE: might produce empty files (which is what we want)
            # Can also deal with empty import (create above if in excl)
            if config['intervals']:
                shell("bedtools intersect -a {} -b {} > {} 2> {{log}}".format(
                    config['intervals'], tmpbed, outbed))
                os.unlink(tmpbed)
            else:
                shutil.move(tmpbed, outbed)

                
rule unit_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        lambda wildcards: expand("{prefix}/{sample}/unit-{unit}.bwamem.bam",
                                 prefix=wildcards.prefix,
                                 sample=wildcards.sample,
                                 unit=config['samples'][wildcards.sample])
    output:
        temp('{prefix}/{sample}/{sample}.bwamem.bam')
    log:
        '{prefix}/{sample}/{sample}.log'
    message:
        "Merging units to {output}"
    threads:
        8
    run:
        # readgroup and pg now different, so make PG and RG uniq (default)
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log};")
               

rule mutect_per_region:
    input:
        nbam = os.path.join(NORMAL_DIR, 'normal.bwamem.dedup.realn.recal.bam'),
        nbai = os.path.join(NORMAL_DIR, 'normal.bwamem.dedup.realn.recal.bam.bai'),
        tbam = os.path.join(TUMOR_DIR, 'tumor.bwamem.dedup.realn.recal.bam'),
        tbai = os.path.join(TUMOR_DIR, 'tumor.bwamem.dedup.realn.recal.bam.bai'),
        # FIXME bed = os.path.join(RESULT_OUTDIR, "interval_wo_excl.bed"),
        reffa = config['references']['genome'],
        refidx = config['references']['genome'] + ".fai",
        dbsnp = config['references']['dbsnp'],
        cosmic = config['references']['cosmic'],
        bed = os.path.join(RESULT_OUTDIR, "chr.split.{ctr}.bed") # see prep_bed_files
    output:
        vcf = temp("{prefix}/mutect.{ctr}.vcf"),
        vcfidx = temp("{prefix}/mutect.{ctr}.vcf.idx"),# just listed to get them removed
        out = temp("{prefix}/mutect.{ctr}.txt"),
        cov = temp("{prefix}/mutect.{ctr}.wig")
    log:
        "{prefix}/mutect.{ctr}.log"
    message:
        "Calling somatic variants with MuTect"
    params:
        frac_cont_arg = "--fraction_contamination {}".format(config["frac_cont"]) if config.get("frac_cont") else ""
    threads:
        # purely due to our java/qsub problem which seemingly limits vm per core
        2
    shell:
        # https://www.broadinstitute.org/cancer/cga/mutect_run
        #  --enable_extended_output
        'MUTECT_THREADS={threads} MUTECT_MEM=8g mutect_wrapper'
        ' --reference_sequence {input.reffa}'
        ' -I:normal {input.nbam} -I:tumor {input.tbam}'
        ' {params.frac_cont_arg}'
        ' --dbsnp {input.dbsnp} --cosmic {input.cosmic}'
        ' --intervals {input.bed}'
        ' --coverage_file {output.cov}'
        ' --out {output.out} --vcf {output.vcf}'
        ' >& {log}'

        
rule mutect_combine:
    input:
        vcf = expand("{{prefix}}/mutect.{ctr}.vcf", ctr=range(config["references"]["num_chroms"])),
        out = expand("{{prefix}}/mutect.{ctr}.txt", ctr=range(config["references"]["num_chroms"])),
        cov = expand("{{prefix}}/mutect.{ctr}.wig", ctr=range(config["references"]["num_chroms"])),
    output:
        vcf = temp("{prefix}/mutect.vcf"),
        out = "{prefix}/mutect.txt.gz",
        cov = "{prefix}/mutect.wig.gz",
    log:
        os.path.join(VARIANTS_DIR, "mutect_combine.log")
    message:
        "Combining results"
    threads:
        1
    #params:
    #    vcf_0 = lambda wildcards: "{prefix}/mutect.{ctr}.vcf".format(prefix=wildcards.prefix, ctr=0),
    #    vcf_1plus = lambda wildcards: expand("{prefix}/mutect.{ctr}.vcf",
    #                                         prefix=wildcards.prefix, ctr=range(1, config["references"]["num_chroms"]))
    # " grep -m 1 '##GATKCommandLine=' {params.vcf_1plus} >> $tmpvcf; "
    shell:
        # combine and gzip files. remove most header from vcf's except first
        "{{ cat {input.out} | gzip > {output.out}; "
        " cat {input.cov} | gzip > {output.cov}; "
        " grep '^#' {input.vcf[0]} > {output.vcf}; "
        " grep -h -v '^#' {input.vcf} >> {output.vcf}; }} >& {log}"   

    
rule mutect_pass:
    input:
        "{prefix}.vcf.gz"
    output:
        "{prefix}.PASS.vcf.gz",
    log:
         "{prefix}.PASS.log",
    message:
        "Extracting only passed variants"
    threads:
        1
    shell:
        "bcftools view -O z -o {output} -f PASS {input} >& {log}"   

