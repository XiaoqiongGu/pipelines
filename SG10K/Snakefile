import os

from snakemake.utils import report

# for logging
from datetime import datetime
import getpass
import subprocess
import socket
from collections import namedtuple

RESULT_OUTDIR = './out'

def getuser():
    return getpass.getuser()


# FIXME could be exported to same directory where Snakefile resides
class ElmLogging(object):
    """
    NOTE:
    - all log lines need all fields
    - one line per runid and lane
    """

   
    @staticmethod
    def get_hostname():
        return socket.gethostname()

    
    @staticmethod
    def disk_usage(path):
        """disk usage via du"""
        return int(subprocess.check_output(['du','-s', path]).split()[0])

    
    @staticmethod
    def timestamp():
        """returns iso timestamp down to ms"""
        return datetime.now().isoformat()

    
    def __init__(self,
                 script_name,# used as logging prefix. can be dummy
                 result_outdir,# where results are stored
                 library_id,
                 run_id,
                 lane_id,
                 pipeline_name,
                 pipeline_version,
                 site,
                 instance_id,
                 submitter,
                 log_path,# main logging file
             ):
        """FIXME:add-doc"""
        
        elmlogdir = os.getenv('RPD_ELMLOGDIR')
        assert elmlogdir, ("RPD_ELMLOGDIR undefined")
        
        pipelogdir = os.path.join(elmlogdir, pipeline_name)
        assert os.path.exists(pipelogdir), (
            "pipeline log dir {} doesn't exist".format(pipelogdir))

        # timestamp just a way to make it unique
        logfile = os.path.join(pipelogdir, self.timestamp() + ".log")
        assert not os.path.exists(logfile)
        # claim name immediately
        open(logfile, 'w').close()
        self.logfile = logfile

        # only used as logging prefix (not even parsed by ELM)
        self.script_name = script_name
        # required for computing library_file_size
        self.result_outdir = result_outdir
        
        # json-like values
        self.fields = OrderedDict()
        # caller provided
        self.fields['library_id'] = library_id
        self.fields['run_id'] = run_id
        self.fields['lane_id'] = lane_id
        self.fields['pipeline_name'] = pipeline_name
        self.fields['pipeline_version'] = pipeline_version
        self.fields['site'] = site
        self.fields['instance_id'] = instance_id
        self.fields['submitter'] = submitter
        self.fields['log_path'] = log_path
        # internally computed
        self.fields['library_file_size'] = None
        self.fields['status_id'] = None

        
    def write_event(self):
        """write one logging event to file
        """
        with open(self.logfile, 'a') as fh:
            timestr = datetime.now().strftime('%c')
            # convert None to 'NA' and all to str
            jsonstr = json.dumps({k: str(v) if v else "NA"
                                  for (k, v) in self.fields.items()})
            fh.write('[{}] [{}] [{}] [EVENTLOG] "{}"\n'.format(
                timestr, self.get_hostname(), self.script_name, jsonstr))

        
    def start(self):
        """Start ELM logging using config values
        """
        self.fields['status_id'] = 5;#startup
        self.write_event()
        

    def stop(self, success):
        """Finalize ELM logging
        """
        if success:
            self.fields['status_id'] = 6;#done
        else:
            self.fields['status_id'] = 7;#troubleshooting
        self.fields['library_file_size'] = self.disk_usage(
            self.result_outdir)
        self.write_event()
            
                
# hack until we have onstart(): see
# https://groups.google.com/forum/#!topic/snakemake/kq3wbSNOFow
#
if not '--dryrun' in sys.argv:
    elm_logger = ElmLogging(
        workflow.snakefile, RESULT_OUTDIR,
        'FIXME:library_id', 'FIXME:run_id', 'FIXME:lane_id',
        config['ELM']['pipeline_name'], config['ELM']['pipeline_version'],
        config['ELM']['site'], "FIXME:instance_id", getuser(), 'FIXME:log')
    
    elm_logger.start()


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")


include: "rules/samtools.rules"
#include: "rules/bwa.rules"
#include: "rules/bedtools.rules"


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""


onsuccess:
    elm_logger.stop(True)
onerror:
    elm_logger.stop(False)

    
rule final:
  input:
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.idxstats.txt'),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.maprate.txt'),
        expand(os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.{race}.selfSM'), race=config['references']['cont_vcfs']),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bam'),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bamstats/stats_plot.html')
  message:
        """
        Pipeline run successfully completed
        
        FIXME:tests missing
        FIXME:report missing
        """
  # if output is created here, deleting the 'input' will not result in
  # rerun so it's best to not create any fake output files here
  #output:  'COMPLETE'
  #shell:   'touch {output}'


rule contamination_check:
    input:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.bam'),
        bai = os.path.join(RESULT_OUTDIR, '{sample}.bam.bai'),
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
    output:
        # assuming default option --self
        bam = os.path.join(RESULT_OUTDIR, '{sample}.{race}.selfSM')
    params:
        outbase = os.path.join(RESULT_OUTDIR, '{sample}.{race}')
    message:
        "Checking for contamination"
    benchmark:# should have same name as rule
        'benchmark/contamination_check.txt'
    shell:
        # NOTE: defaults tuned for shallow WGS
        # See http://genome.sph.umich.edu/wiki/VerifyBamID#What_the_default_option_does
        # run for sample and read-groups, i.e. don't use --ignoreRG
        "verifyBamID --vcf {input.vcf} --bam {input.bam} --out {params.outbase} --noPhoneHome;"

        
rule bq_recal:
    """Use bamutils for base quality recalibration with bamUtils

    recommended use without deduper: http://genome.sph.umich.edu/wiki/BamUtil:_recab

    Bottleneck because single thread process! See https://github.com/statgen/bamUtil/issues/21
    """
    input:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.bam'),
        reffa = config['references']['genome'],
        dbsnp = config['references']['dbsnp']
    output:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.recal.bam'),
        qemp = os.path.join(RESULT_OUTDIR, '{sample}.recal.qemp.bam')
    message:
        "Base quality recalibration with bamUtils"
    benchmark:# should have same name as rule
        'benchmark/bq_recal.txt'
    shell:
        # recommended use is --storeQualTag OQ but we need the BAMs to be small
        "bam recab --in {input.bam} --out {output.bam} --refFile {input.reffa} --dbsnp {input.dbsnp} --maxBaseQual 40 --noPhoneHome"
    
    
rule sample_merge:
    """
    Merge bam files for multiple units into one for the given sample.
    If the sample has only one unit, a symlink will be created.
    """
    input:
        expand(os.path.join(RESULT_OUTDIR, '{unit}.bwamem.fixmate.mdups.srt.bam'), unit=config["units"])
    threads:
        16
    output:
        temp(os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.bam'))
    message:
        "Merging files"
    benchmark:# should have same name as rule
        'benchmark/sample_merge.txt'
    run:
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input};")
        else:
            shell("ln -s {input} {output} && touch -h {output}")


# Expecting SE/PE input read length >70 (BWA-MEM limitation)
rule map_mdups_sort:
    """fixmate only works on name sorted files. ignores secondary 
    alignments, i.e. safe to use with bwa mem -M:
    http://sourceforge.net/p/samtools/mailman/message/30556922/
         
    samtools sort might need control of max thread memory to not go 
    over limit for v1.3 it's 768M. if we use 16 threads this amounts 
    to max 12.3GB (on top of whatever else is running).
	
    using samtools instead of sambamba for view and sort:
    http://genomespot.blogspot.sg/2015/03/sambamba-vs-samtools.html says
    runtime difference are not too huge and samtools is the conservative
    choice anyway

    Define temporary sorting out prefix to avoid nameclashes (default
    -.XXX.bam for stdin)
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: config["units"][wildcards.unit]
    output:
        bam=temp(os.path.join(RESULT_OUTDIR, '{unit}.bwamem.fixmate.mdups.srt.bam'))
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        sort_mem='500M'
    message:
        'Aligning PE reads, fixing mate information, marking duplicates and converting to sorted BAM'
    threads:
        16
    benchmark:# should have same name as rule
        'benchmark/map_mdups_sort.txt'
    #log:
    #    # should have same name as rule
    #    'logs/map_mdups_sort.txt'
    shell:
        "bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\tID:{wildcards.unit}\tPL:{config[platform]}\tPU:PU-{wildcards.unit}\tLB:LB-{config[sample]}\tSM:{config[sample]}\tCN:GIS'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        " samtools fixmate -O sam - - |"
        " samblaster {params.mark_short_splits} |"
        " samtools view -@ {threads} -bu -o - |"
        " samtools sort -@ {threads} -m {params.sort_mem} -o {output.bam} -T {output.bam}.tmp -"

# FIXME rule report:
# write program versions
# how it works
