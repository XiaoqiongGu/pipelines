import os
from datetime import datetime
from collections import OrderedDict()
from snakemake.utils import report


# FIXME could be exported to same directory where Snakefile resides
class ElmLogging(object):
    """FIXME-adddoc
    """
    
    @staticmethod
    def timestamp():
        """returns iso timestamp down to ms"""
        return datetime.now().isoformat()

    
    def __init__(self, pipeline_name):
        """FIXME:add-doc"""
        
        elmlogdir = os.getenv('RPD_ELMLOGDIR')
        assert elmlogdir, ("RPD_ELMLOGDIR undefined")
        
        pipelogdir = os.path.join(elmlogdir, pipeline_name)
        assert os.path.exists(pipelogdir), (
            "pipeline log dir {} doesn't exist".format(pipelogdir))

        # timestamp just a way to make it unique
        logfile = os.path.join(pipelogdir, self.timestamp() + ".log")
        assert not os.path.exists(logfile)
        # claim name immediately
        open(logfile, 'w').close()
        self.logfile = logfile


    def write(self, key, value):
        with open(self.logfile, 'a') as fh:
            fh.write('{} [EVENTLOG] "{}" : "{}"\n'.format(self.timestamp(), key, value))

        
    def start(self):
        """Start ELM logging using config values
        """
        with open(self.logfile, 'a') as fh:
            for k in ['libraryID', 'runID', 'laneID', 'pipeLineName',
                      'pipeLineVersion', 'site']:
                assert k in config['ELM']
                self.write(k, config['ELM'][k])                
            self.write("statusID", 5)# == in analysis (startup)
                    

    def stop(self, success):
        """Finalize ELM logging
        """
        with open(self.logfile, 'a') as fh:
            if success:
                status = 6#done
            else:
                status = 7#troubleshooting
            self.write("statusID", status)
                                         
            # FIXME write library_file_size
            # FIXME write status_id depending on success
            # FIXME write jids
            # FIXME write head jid as instance_id
            
                
elm_logger = ElmLogging(config['ELM']['pipeLineName'])
elm_logger.start()


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source env.rc;")


include: "rules/samtools.rules"
#include: "rules/bwa.rules"
#include: "rules/bedtools.rules"


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""


onsuccess:
    elm_logger.stop(success)
onerror:
    elm_logger.stop(not success)

    
rule final:
  input:
        "out/" + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.idxstats.txt',
        "out/" + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.maprate.txt',
        expand("out/" + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.{race}.selfSM', race=config['references']['cont_vcfs']),
        "out/" + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bam',
        "out/" + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bamstats/stats_plot.html'
  message:
        """
        Pipeline run successfully completed
        
        FIXME:tests missing
        FIXME:report missing
        """
  # if output is created here, deleting the 'input' will not result in
  # rerun so it's best to not create any fake output files here
  #output:  'COMPLETE'
  #shell:   'touch {output}'


rule contamination_check:
    input:
        bam = 'out/{sample}.bam',
        bai = 'out/{sample}.bam.bai',
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
    output:
        # assuming default option --self
        bam = 'out/{sample}.{race}.selfSM'
    params:
        outbase = 'out/{sample}.{race}'
    message:
        "Checking for contamination"
    benchmark:# should have same name as rule
        'benchmark/contamination_check.txt'
    shell:
        # NOTE: defaults tuned for shallow WGS
        # See http://genome.sph.umich.edu/wiki/VerifyBamID#What_the_default_option_does
        # run for sample and read-groups, i.e. don't use --ignoreRG
        "verifyBamID --vcf {input.vcf} --bam {input.bam} --out {params.outbase} --noPhoneHome;"

        
rule bq_recal:
    """Use bamutils for base quality recalibration with bamUtils

    recommended use without deduper: http://genome.sph.umich.edu/wiki/BamUtil:_recab

    Bottleneck because single thread process! See https://github.com/statgen/bamUtil/issues/21
    """
    input:
        bam = 'out/{sample}.bam',
        reffa = config['references']['genome'],
        dbsnp = config['references']['dbsnp']
    output:
        bam='out/{sample}.recal.bam',
        qemp='out/{sample}.recal.qemp.bam'
    message:
        "Base quality recalibration with bamUtils"
    benchmark:# should have same name as rule
        'benchmark/bq_recal.txt'
    shell:
        # recommended use is --storeQualTag OQ but we need the BAMs to be small
        "bam recab --in {input.bam} --out {output.bam} --refFile {input.reffa} --dbsnp {input.dbsnp} --maxBaseQual 40 --noPhoneHome"
    
    
rule sample_merge:
    """
    Merge bam files for multiple units into one for the given sample.
    If the sample has only one unit, a symlink will be created.
    """
    input:
        expand("out/{unit}.bwamem.fixmate.mdups.srt.bam", unit=config["units"])
    threads:
        16
    output:
        temp('out/' + config['sample'] + '.bwamem.fixmate.mdups.srt.merged.bam')
    message:
        "Merging files"
    benchmark:# should have same name as rule
        'benchmark/sample_merge.txt'
    run:
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input};")
        else:
            shell("ln -s {input} {output} && touch -h {output}")


# Expecting SE/PE input read length >70 (BWA-MEM limitation)
rule map_mdups_sort:
    """fixmate only works on name sorted files. ignores secondary 
    alignments, i.e. safe to use with bwa mem -M:
    http://sourceforge.net/p/samtools/mailman/message/30556922/
         
    samtools sort might need control of max thread memory to not go 
    over limit for v1.3 it's 768M. if we use 16 threads this amounts 
    to max 12.3GB (on top of whatever else is running).
	
    using samtools instead of sambamba for view and sort:
    http://genomespot.blogspot.sg/2015/03/sambamba-vs-samtools.html says
    runtime difference are not too huge and samtools is the conservative
    choice anyway

    Define temporary sorting out prefix to avoid nameclashes (default
    -.XXX.bam for stdin)
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: config["units"][wildcards.unit]
    output:
        bam=temp("out/{unit}.bwamem.fixmate.mdups.srt.bam")
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        sort_mem='500M'
    message:
        'Aligning PE reads, fixing mate information, marking duplicates and converting to sorted BAM'
    threads:
        16
    benchmark:# should have same name as rule
        'benchmark/map_mdups_sort.txt'
    #log:
    #    # should have same name as rule
    #    'logs/map_mdups_sort.txt'
    shell:
        "bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\tID:{wildcards.unit}\tPL:{config[platform]}\tPU:PU-{wildcards.unit}\tLB:LB-{config[sample]}\tSM:{config[sample]}\tCN:GIS'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        " samtools fixmate -O sam - - |"
        " samblaster {params.mark_short_splits} |"
        " samtools view -@ {threads} -bu -o - |"
        " samtools sort -@ {threads} -m {params.sort_mem} -o {output.bam} -T {output.bam}.tmp -"

# FIXME rule report:
# write program versions
# how it works
