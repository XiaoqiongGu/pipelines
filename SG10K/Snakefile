import os
import readunits
from snakemake.utils import report
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit


RESULT_OUTDIR = './out'


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""

# read group functions following
# http://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")


include: "../rules/logging.rules"
include: "../rules/samtools.rules"

    
rule final:
    input:
        # NOTE changes here will likely have to be reflected in the report rule as well
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.idxstats.txt'),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.maprate.txt'),
        expand(os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.{race}.selfSM'), race=config['references']['cont_vcfs']),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bam'),
        os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bamstats/stats_plot.html'),
        "report.html"
    message:
        """
        Pipeline run successfully completed
        """
    # Set no output in final rule. Otherwise deletion of any input will not result in a rerun


rule report:
    input:
        # NOTE should roughly match final rule?!
        bam=os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bam'),
        basic_map_stats=os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.bamstats/stats_plot.html'),
        cont_results=expand(os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.recal.{race}.selfSM'), race=config['references']['cont_vcfs'])
    output: html="report.html"
    run:
    	# FIXME duplication with README
        report("""
        ==========================================================================================
        {config[ELM][pipeline_name]} ({config[ELM][pipeline_version]}) report for {config[sample]}
        ==========================================================================================
        
        This is the mapping pipeline for the SG10K project workflow. It is
        specifically tailored for SG10K samples and therefore not recommended
        to use it for anything else. Specifically, it's designed for shallow
        WGS, uses the gotcloud reference bundles and performs contamination
        checks against the three major ethnicities in Singapore.
        
        - All results can be found in the directory called {RESULT_OUTDIR}
        - Main output is a BAM file (with base qualities recalibrated): {input.bam}
        - Basic mapping statistics can be found in {input.basic_map_stats}
        - Contamination results can be found in {input.cont_results}
        - The full configfile_ containing all parameters, including program versions and settings is attached to this report
        """, output.html, metadata="Research Pipeline Development Team (rpd@mailman.gis.a-star.edu.sg)", configfile="conf.yaml")
        # doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch
        # FIXME hardcoded path to configfile
        
rule contamination_check:
    input:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.bam'),
        bai = os.path.join(RESULT_OUTDIR, '{sample}.bam.bai'),
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        #vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
        vcf = lambda wildcards: config["references"]["cont_vcfs"][wildcards.race]
    output:
        # assuming default option --self
        bam = os.path.join(RESULT_OUTDIR, '{sample}.{race}.selfSM')
    params:
        outbase = os.path.join(RESULT_OUTDIR, '{sample}.{race}')
    message:
        "Checking for contamination"
    benchmark:# should have same name as rule
        'benchmark/contamination_check.txt'
    shell:
        # NOTE: defaults tuned for shallow WGS
        # See http://genome.sph.umich.edu/wiki/VerifyBamID#What_the_default_option_does
        # Chaolong wanted specials settings (see email from 2016-02-22)
        # run for sample and read-groups, i.e. don't use --ignoreRG
        "verifyBamID --vcf {input.vcf} --bam {input.bam} --out {params.outbase} --noPhoneHome --precise --maxDepth 100 --minMapQ 20 --minQ 20 --maxQ 100;"

        
rule bq_recal:
    """Use bamutils for base quality recalibration with bamUtils

    recommended use without deduper: http://genome.sph.umich.edu/wiki/BamUtil:_recab

    Bottleneck because single thread process! See https://github.com/statgen/bamUtil/issues/21
    """
    input:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.bam'),
        reffa = config['references']['genome'],
        dbsnp = config['references']['dbsnp']
    output:
        bam = os.path.join(RESULT_OUTDIR, '{sample}.recal.bam'),
        qemp = os.path.join(RESULT_OUTDIR, '{sample}.recal.bam.qemp')
    message:
        "Base quality recalibration with bamUtils"
    benchmark:# should have same name as rule
        'benchmark/bq_recal.txt'
    shell:
        # recommended use is --storeQualTag OQ but we need the BAMs to be small
        "bam recab --in {input.bam} --out {output.bam} --refFile {input.reffa} --dbsnp {input.dbsnp} --maxBaseQual 40 --noPhoneHome"
    
    
rule sample_merge:
    """
    Merge bam files for multiple units into one for the given sample.
    If the sample has only one unit, a symlink will be created.
    """
    input:
        expand(os.path.join(RESULT_OUTDIR, '{unit}.bwamem.fixmate.mdups.srt.bam'), unit=config["units"])
    threads:
        16
    output:
        temp(os.path.join(RESULT_OUTDIR, config['sample'] + '.bwamem.fixmate.mdups.srt.merged.bam'))
    message:
        "Merging files"
    benchmark:# should have same name as rule
        'benchmark/sample_merge.txt'
    run:
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input};")
        else:
            # hard link should work even if input is temp and later deleted
            shell("ln {input} {output}")


# Expecting SE/PE input read length >70 (BWA-MEM limitation)
rule map_mdups_sort:
    """fixmate only works on name sorted files. ignores secondary 
    alignments, i.e. safe to use with bwa mem -M:
    http://sourceforge.net/p/samtools/mailman/message/30556922/
         
    samtools sort might need control of max thread memory to not go 
    over limit for v1.3 it's 768M. if we use 16 threads this amounts 
    to max 12.3GB (on top of whatever else is running).
	
    using samtools instead of sambamba for view and sort:
    http://genomespot.blogspot.sg/2015/03/sambamba-vs-samtools.html says
    runtime difference are not too huge and samtools is the conservative
    choice anyway

    Define temporary sorting out prefix to avoid nameclashes (default
    -.XXX.bam for stdin)

    Setting read groups correctly is tricky and also depends on
    downstream programs. See
    e.g. http://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups
    For example for BQSR PU takes precedence over ID. PU should contain lane

    We don't mark duplicate again after merging because it's a PCR
    free library to optical duplicates matter the most
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: fastqs_from_unit(config["units"][wildcards.unit])
    output:
        bam=temp(os.path.join(RESULT_OUTDIR, '{unit}.bwamem.fixmate.mdups.srt.bam'))
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        sort_mem='500M',
        rg_id=lambda wildcards: config["units"][wildcards.unit]['rg_id'],# always set
        lib_id=lambda wildcards: gen_rg_lib_id(config["units"][wildcards.unit]),
        pu_id=lambda wildcards: gen_rg_pu_id(config["units"][wildcards.unit])
    message:
        'Aligning PE reads, fixing mate information, marking duplicates and converting to sorted BAM'
    threads:
        8
    benchmark:# should have same name as rule
        'benchmark/map_mdups_sort.txt'
    shell:
        "bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\\tID:{params.rg_id}\\tPL:{config[platform]}\\tPU:{params.pu_id}\\tLB:{params.lib_id}\\tSM:{config[sample]}\\tCN:GIS'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        " samtools fixmate -O sam - - |"
        " samblaster {params.mark_short_splits} |"
        " samtools view -@ {threads} -bu -o - |"
        " samtools sort -@ {threads} -m {params.sort_mem} -o {output.bam} -T {output.bam}.tmp -"
