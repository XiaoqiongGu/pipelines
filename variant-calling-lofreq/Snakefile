# standard library imports
#
import os

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit, get_sample_for_unit


RESULT_OUTDIR = './out'


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""


def mark_dups_pipe_cmd(before="", after=""):
    """FIXME review once MARK_SHORT_SPLITS is in config

    before and after are commands added before and after samblaster
    and can be used e.g. for conversion from BAM to BAM (samblaster needs SAM)

    return command will always end in pipe
    """
    
    if config['mark_dups']:
        if before:
            cmd = "{} | ".format(before)
        else:
            cmd = ""
        cmd += " samblaster {MARK_SHORT_SPLITS} | "
        if after:
            cmd += " {} | ".format(after)
        return cmd
    else:
        return ""



# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")


include: "../rules/logging.rules"
include: "../rules/samtools.rules"


rule final:
    input:
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.snps.vcf.gz'),
               sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.indels.vcf.gz'),
               sample=config['samples'])


rule vcf_split:
    input:
        vcf = '{prefix}.both.vcf.gz'
    output:
        snps = '{prefix}.snps.vcf.gz',
        indels = '{prefix}.indels.vcf.gz'
    message:
        "Splitting vcf into SNPs and Indels"
    threads:
        2
    shell:
        "zgrep -v '^GL' {input.vcf} | bcftools view -v snps - -O z -o {output.snps};"
        "tabix {output.snps};"
        "zgrep -v '^GL' {input.vcf} | bcftools view -v indels - -O z -o {output.indels};"
        "tabix {output.indels};"


rule lofreq_call:
    input:
        bam = '{prefix}.bam',
        bai = '{prefix}.bam.bai',
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac"
    output:
        vcf = temp('{prefix}.both.vcf.gz')
    message:
        "Calling variants with LoFreq"
    threads:
        8
    benchmark:# should have same name as rule
        'benchmark/lofreq_call.txt'
    shell:
        "lofreq call-parallel --pp-threads {threads} --call-indels -f {input.reffa} -o {output.vcf} {input.bam}"

    
rule lacer_apply:
    input:
        bam = '{prefix}.bam',
        table = '{prefix}.lacer.table'
    output:
        bam = '{prefix}.lacer.bam'
    message:
        "Applying lacer recalibration to BAM"
    threads:
        1
    benchmark:
        'benchmark/lacer_recal'
    shell:
        'lacepr {input.bam} {input.table} {output.bam}'
    
        
rule lacer_table:
    input:
        bam = '{prefix}.bam',
        bai = '{prefix}.bam.bai',
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac"
    output:
        table = '{prefix}.lacer.table'
    message:
        "Computing recalibration table with Lacer"
    threads:
        8
    params:
        stopbases = 1000000
    benchmark:
        'benchmark/lacer_table'
    shell:
        'lacer.pl -randomize -threads {threads} -stopbases {params.stopbases}'
        ' -bam {input.bam} -reference {input.reffa} -outfile {output.table}'


rule unit_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        # the following will try to create files called {{prefix}}!?
        #lambda wildcards: expand('{{prefix}}/unit-{unit}.bwamem.merged.lofreq.bam',
        #                         unit=config['samples'][wildcards.sample])
        lambda wildcards: expand(os.path.join(RESULT_OUTDIR, "unit-{unit}.bwamem.merged.lofreq.bam"),
                                 unit=config['samples'][wildcards.sample])
    output:
        '{prefix}/sample-{sample}.bwamem.lofreq.bam'
    message:
        "Merging units to samples"
    threads:
        8
    benchmark:# should have same name as rule
        'benchmark/unit_merge.txt'
    run:
        # readgroup and pg now different, so make PG and RG uniq (default)
        # not running mark_dups_pipe_cmd again since not read name sorted anymore
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input};")
        else:
            shell("ln {input} {output}")



rule split_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        bams=expand('{{prefix}}.chrsplit.{ctr}.lofreq.bam',
                    ctr=range(config["references"]["num_chroms"]+1))
                    # +1 for unaligned reads
    output:
        bam = temp('{prefix}.merged.lofreq.bam')
    message:
        "Merging split units"
    threads:
        4
    benchmark:# should have same name as rule
        'benchmark/bam_merge.txt'
    run:
        if len(input) > 1:
            # same readgroup and pg, so combine colliding PG and RG
            shell("samtools merge -c -p -@ {threads} {output} {input};")
        else:
            shell("ln {input} {output}")


rule lofreq_massage_sort:
    """Runs BAM through full LoFreq preprocessing pipeline,
    i.e. viterbi, alnqual, indelqual, followed by sort (required by
    viterbi). 

    WARNING: running this on sorted input files will be inefficient
    because of constant reloading of the reference
    """
    input:
        bam = '{prefix}.bwamem.chrsplit.{ctr}.bam',
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac"
    output:
        bam=temp('{prefix}.bwamem.chrsplit.{ctr}.lofreq.bam')
    params:
        sort_mem='500M'
    message: "Preprocessing BAMs with LoFreq"
    shell:
        "lofreq viterbi -f {input.reffa} {input.bam} | "
        " lofreq alnqual -u - {input.reffa} | "
        " lofreq indelqual --dindel -f {input.reffa} - | "
        " samtools sort -m {params.sort_mem} -o {output.bam} -T {output.bam}.tmp -"


#def get_outprefix_for_map_mdups_split(wildcards):
#    return '{prefix}/unit-{unit}.bwamem.chrsplit'.format(
#        wildcards['prefix'], wildcards['unit'])
            
## WARN: Copy&Paste from BWA-MEM!
## - replaced sorted with split_bam_by_chr and changed out accordingly
## - removed fixmate (no points since we run viterbi later)
## - increased threads (since we don't sort etc.)
rule map_mdups_split:
    """
    - Setting read groups correctly is tricky and also depends on downstream programs. 
      See e.g. http://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups
      For example for BQSR PU takes precedence over ID. PU should contain lane.
    - More threads mean more memory because of sorting
    - This originated from the equally named SG10K rule
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: fastqs_from_unit(config["readunits"][wildcards.unit])
    output:
        bams=temp(expand('{{prefix}}/unit-{{unit}}.bwamem.chrsplit.{ctr}.bam',
                         ctr=range(config["references"]["num_chroms"]+1)))
                         # +1 for unaligned reads
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        rg_id=lambda wildcards: config["readunits"][wildcards.unit]['rg_id'],# always set
        lib_id=lambda wildcards: gen_rg_lib_id(config["readunits"][wildcards.unit]),
        pu_id=lambda wildcards: gen_rg_pu_id(config["readunits"][wildcards.unit]),
        #outprefix=lambda wildcards: get_outprefix_for_map_mdups_split(wildcards),
        outprefix=lambda wildcards: '{}/unit-{}.bwamem.chrsplit'.format(wildcards.prefix, wildcards.unit),# keep in sync with input
        sample=lambda wildcards: get_sample_for_unit(wildcards.unit, config)
    message:
        'Aligning, marking duplicates (if set) and splitting per chrom'
    threads:
        # see also BWA-MEM
        32
    benchmark:# should have same name as rule
        'benchmark/map_mdups_split.txt'
    shell:
        "bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\\tID:{params.rg_id}\\tPL:{config[platform]}\\tPU:{params.pu_id}\\tLB:{params.lib_id}\\tSM:{params.sample}\\tCN:GIS'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        + mark_dups_pipe_cmd() +
        " split_bam_by_chr -S -l 0 -o {params.outprefix} -"
        # " samtools view -bu -o - |"
