# standard library imports
#
import os

# third party imports
#
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from readunits import gen_rg_lib_id, gen_rg_pu_id, fastqs_from_unit, get_sample_for_unit


RESULT_OUTDIR = './out'


# FIXME to conf once downstream handling clear
MARK_SHORT_SPLITS="-M"# "-M" or ""


def mark_dups_pipe_cmd(before="", after=""):
    """FIXME review once MARK_SHORT_SPLITS is in config

    before and after are commands added before and after samblaster
    and can be used e.g. for conversion from BAM to BAM (samblaster needs SAM)

    return command will always end in pipe
    """
    
    if config['mark_dups']:
        if before:
            cmd = "{} | ".format(before)
        else:
            cmd = ""
        cmd += " samblaster {MARK_SHORT_SPLITS} | "
        if after:
            cmd += " {} | ".format(after)
        return cmd
    else:
        return ""


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")


include: "../rules/logging.rules"
include: "../rules/samtools.rules"
include: "lofreq.rules"
include: "lacer.rules"


if config['seqtype'] == 'targeted':
    localrules: final, report, vcf_split, lacer_apply, lacer_table
else:
    localrules: final, report, vcf_split


rule final:
    input:
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.snps.vcf.gz'),
               sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.indels.vcf.gz'),
               sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.bamstats/stats.txt'),
               sample=config['samples']),
        "report.html"


rule report:
    input:
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.snps.vcf.gz'),
               sample=config['samples']),
        expand(os.path.join(RESULT_OUTDIR, 'sample-{sample}.bwamem.lofreq.lacer.indels.vcf.gz'),
               sample=config['samples']),
    output: html="report.html"
    params: samplenames=', '.join(config['samples'].keys())
    run:
        workflow_home = os.path.dirname(os.path.realpath(workflow.snakefile))
        readme = "EMPTY"
        with open(os.path.join(workflow_home, "README.rst")) as fh:
            readme = fh.read()
            
        report("""
=================================================================
Pipeline {config[ELM][pipeline_name]} run on {params.samplenames}
=================================================================

Version Info
------------

{config[ELM][pipeline_version]}) 

""" + readme, output.html, metadata="Research Pipeline Development Team (rpd@mailman.gis.a-star.edu.sg)",# **input)
               conf="conf.yaml")
        # from doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch to have at least something



rule vcf_split:
    input:
        vcf = '{prefix}.both.vcf.gz'
    output:
        snps = '{prefix}.snps.vcf.gz',
        indels = '{prefix}.indels.vcf.gz'
    log:
        '{prefix}.split.log'
    message:
        "Splitting vcf into SNPs and Indels"
    threads:
        2
    shell:
        "{{ zgrep -v '^GL' {input.vcf} | bcftools view -v snps - -O z -o {output.snps};"
        " tabix {output.snps};"
        " zgrep -v '^GL' {input.vcf} | bcftools view -v indels - -O z -o {output.indels}; "
        " tabix {output.indels}; }} >& {log};"


rule unit_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        lambda wildcards: expand("{prefix}/unit-{unit}.bwamem.merged.lofreq.bam",
                                 prefix=wildcards.prefix,
                                 unit=config['samples'][wildcards.sample])
    output:
        '{prefix}/sample-{sample}.bwamem.lofreq.bam'
    log:
        '{prefix}/sample-{sample}.bwamem.lofreq.bam.unit_merge.log'        
    message:
        "Merging units to samples"
    threads:
        8
    run:
        # readgroup and pg now different, so make PG and RG uniq (default)
        # not running mark_dups_pipe_cmd again since not read name sorted anymore
        if len(input) > 1:
            shell("samtools merge -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log};")


rule split_merge:
    """
    Merge bam files for multiple units into one for the given sample
    (or copy if just one).
    """
    input:
        bams=expand('{{prefix}}.chrsplit.{ctr}.lofreq.bam',
                    ctr=range(config["references"]["num_chroms"]+1))
        # +1 for unaligned reads
    output:
        bam = temp('{prefix}.merged.lofreq.bam')
    log:
        '{prefix}.merged.lofreq.bam.split_merge.log'
    message:
        "Merging split units"
    threads:
        4
    run:
        if len(input) > 1:
            # same readgroup and pg, so combine colliding PG and RG
            shell("samtools merge -c -p -@ {threads} {output} {input} >& {log};")
        else:
            shell("ln {input} {output} >& {log}")


# WARN: Near identical copy from BWA-MEM
# - replaced sorted with split_bam_by_chr and changed out accordingly
# - removed fixmate (no points since we run viterbi later)
# - increased threads (since we don't sort etc.)
rule map_mdups_split:
    """
    - Setting read groups correctly is tricky and also depends on downstream programs. 
      See e.g. http://gatkforums.broadinstitute.org/gatk/discussion/6472/read-groups
      For example for BQSR PU takes precedence over ID. PU should contain lane.
    - More threads mean more memory because of sorting
    - This originated from the equally named SG10K rule
    """
    input:
        reffa = config['references']['genome'],
        reffai = config['references']['genome'] + ".pac",
        fastqs = lambda wildcards: fastqs_from_unit(config["readunits"][wildcards.unit])
    output:
        bams=temp(expand('{{prefix}}/unit-{{unit}}.bwamem.chrsplit.{ctr}.bam',
                         ctr=range(config["references"]["num_chroms"]+1)))
                         # +1 for unaligned reads
    log:
        '{prefix}/unit-{unit}.bwamem.map.log'
    params:
        mark_short_splits=MARK_SHORT_SPLITS,
        bwa_mem_custom_args=config.get("bwa_mem_custom_args", ""),
        rg_id=lambda wildcards: config["readunits"][wildcards.unit]['rg_id'],# always set
        lib_id=lambda wildcards: gen_rg_lib_id(config["readunits"][wildcards.unit]),
        pu_id=lambda wildcards: gen_rg_pu_id(config["readunits"][wildcards.unit]),
        #outprefix=lambda wildcards: get_outprefix_for_map_mdups_split(wildcards),
        outprefix=lambda wildcards: '{}/unit-{}.bwamem.chrsplit'.format(wildcards.prefix, wildcards.unit),# keep in sync with input
        sample=lambda wildcards: get_sample_for_unit(wildcards.unit, config)
    message:
        'Aligning, marking duplicates (if set) and splitting per chrom'
    threads:
        # see also BWA-MEM
        32
    shell:
        "{{ bwa mem {params.mark_short_splits} -t {threads}"
        " -R '@RG\\tID:{params.rg_id}\\tPL:{config[platform]}\\tPU:{params.pu_id}\\tLB:{params.lib_id}\\tSM:{params.sample}\\tCN:GIS'"
        " {params.bwa_mem_custom_args} {input.reffa} {input.fastqs} |"
        + mark_dups_pipe_cmd() +
        " split_bam_by_chr -S -l 0 -o {params.outprefix} -; }} >& {log}"

