import os
from math import ceil
from snakemake.utils import report
import getpass

from elmlogger import ElmLogging, UnitId, timestamp

RESULT_OUTDIR = './out'

SAMPLESHEET = os.path.join(RESULT_OUTDIR, 'samplesheet.csv')

USEBASES_CFG = os.path.join(RESULT_OUTDIR, 'usesbases.yaml')


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")


def getuser():
    return getpass.getuser()


def bcl2fastq_threads_setting(num_threads):
    """Divide threads meaningfully to the different bcl2fastq 
    """
    demultiplex_threads_frac = 0.2
    process_threads_frac = 0.8
    return " -r 1 -w 1 -d {} -p {}".format(
    	   ceil(demultiplex_threads_frac*num_threads),
	   ceil(process_threads_frac*num_threads))


def get_mux_dirs():
    """returns mux_dir per unit listed in config"""
    return [v['mux_dir'] for k, v in config["units"].items()]


onstart:# available as patched snakemake 3.5.5
    global elm_logger

    if config['ELM']['run_id'] or config['ELM']['library_id'] or config['ELM']['lane_id']:
        unit_ids = [UnitId._make(x) for x in zip(
            config['ELM']['run_id'], config['ELM']['library_id'], config['ELM']['lane_id'])]
    else:
        unit_ids = [UnitId._make(['NA', 'NA', 'NA'])]
        
    elm_logger = ElmLogging(workflow.snakefile,
                            config['ELM']['pipeline_name'],
                            config['ELM']['pipeline_version'],
                            getuser(),#SET_ON_EXEC
                            config['ELM']['site'],
                            timestamp(),# crutch: master jid would be best, but site dependent. log location unknown. how to treat manual runs?
                            config['ELM']['log_path'],#SET_ON_EXEC
                            RESULT_OUTDIR,
                            unit_ids)
    elm_logger.start()

        
    sys.stderr.write("onstart: FIXME mongodb initiated\n")

onsuccess:
    elm_logger.stop(True)
    sys.stderr.write("onsuccess: FIXME mongodb update (success)\n")
onerror:
    elm_logger.stop(False)
    sys.stderr.write("onerror: FIXME mongodb update (fail)\n")


rule final:
    input:
	# here, expand creates a list of expected output folders/files based on 'units'
	# defined in config (actually Project_Y/Sample_X)
        #
        # dependency per mux on bcl2fastq, so that it runs per mux
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'fastqc.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'srasubmission.SUCCESS'),
               muxdir=get_mux_dirs()),
        "report.html"
    message:
        """
        Pipeline run successfully completed
        """
    # Set no output in final rule. Otherwise deletion of any input will not result in a rerun


rule report:
    input:
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),

    output: html="report.html"
    run:
        # FIXME duplication with README
        report("""
        ==========================================================================================
        {config[ELM][pipeline_name]} ({config[ELM][pipeline_version]}) report for FIXME:runid
        ==========================================================================================

        FIXME:text        
        """, output.html, metadata="Research Pipeline Development Team (rpd@mailman.gis.a-star.edu.sg)", configfile="conf.yaml")
        # doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch
        # FIXME hardcoded path to configfile


rule bcl2fastq:
    """Running bcl2fastq with dynamically split threads

    https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/bcl2fastq/bcl2fastq2-v2-17-software-guide-15051736-g.pdf
    """
    input: 
        rundir = config['rundir'],
        samplesheet = config['samplesheet_csv'],
    output:
        flag = os.path.join(RESULT_OUTDIR, "{muxdir}", "bcl2fastq.SUCCESS"),
    message: "Running bcl2fastq/Demultiplexing"
    threads: 32
    params:
        usebases = config['usebases_arg'],
        barcode_mismatches = lambda wildcards: '--barcode-mismatches {}'.format(config['units'][wildcards.muxdir]['barcode_mismatches']),
        tiles = lambda wildcards: ''.join(["{},".format(lane_id) for lane_id in config['units'][wildcards.muxdir]['lane_ids']])[:-1]
        
    benchmark: "benchmark/bcl2fastq.txt"
    run:
        #cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        #shell(cmd)
        #shell('echo {} > {}'.format(cmd, output))
        cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        shell(cmd)
        shell("touch {output}")
      
       
rule sra_submission:
    """Submitting to SRA"""
    input: '{prefix}/bcl2fastq.SUCCESS'
    output: '{prefix}/srasubmission.SUCCESS'
    message: "Archival submission"
    threads: 1
    benchmark: 'benchmark/sra_submission.txt'
    run:
        import os,sys
        import requests
        import requests
        import json
        import time
        
        sys.stderr.write("FIXME temp hack making sra_submission to appear to work\n")
        # Avoid snakemake.exceptions.RuleException: Output files are older than input files
        # which is likely an NFS issue.
        # see also https://bitbucket.org/snakemake/snakemake/issues/300/race-condition-waiting-for-files-on-nfs
        # for now, simply wait/sleep first
        #time.sleep(30)
        
        for f in output:
            req = {}
            req_code = {}
            data = {}
            project_path = os.path.dirname(f)
            project_id = project_path.split("/")[-1].split('_')[-1]
            run_id =  config['units'][project_path.split("/")[-1]]['run_id']
            email = "veeravallil@.gis.a-star.edu.sg"        
            for child in os.listdir(project_path):
                sample_path = os.path.join(project_path, child)
                if os.path.isdir(sample_path):
                    abs_sample_path = os.path.abspath(sample_path)
                    sample_id = sample_path.split("/")[-1].split('_')[-1]
                    data['libraryId'] = sample_id
                    data['muxId'] = project_id
                    data['runId'] = run_id
                    data['path'] = [abs_sample_path]
                    data['email'] = [email]
                    req_code['reqCode'] = "SA-A002-009"
                    req_code['SA-A002-009'] = data
                    req['Request'] = req_code
                    test_json = json.dumps(req)
                    data_json = test_json.replace("\\", "");
                    print(data_json)
                    rest_url =  "http://dlap30v:9002/gismart/search"
                    response = requests.post(rest_url, data=data_json)
                    print (response.status_code)
                    if response.status_code != requests.codes.ok:
                        response.raise_for_status()
            with open(f, 'a') as fh:
                fh.write("FIXME temp hack making sra_submission to appear to work\n")
        return
    
    
rule fastqc:
    """fastqc per muxdir. note: this will not make full use of
    parallelization of many subdirs exist simply because we don't keep
    sample information
    """
    input: '{muxdir}/bcl2fastq.SUCCESS'
    output: '{muxdir}/fastqc.SUCCESS'
    threads: 16
    message: "Running fastqc on {input}"
    benchmark: 'benchmark/fastqc.txt'
    shell:
        # need to be able to deal with empty directories
        # assume success and delete success flag on failure
        "touch {output};"
        "for f in $(find $(dirname {input}) -name \*fastq.gz); do"
        "    fastqc -t {threads} $f || rm {output};"
        "done"





