import os
from math import ceil
from getpass import getuser

import yaml
# only dump() and following do not automatically create aliases
yaml.Dumper.ignore_aliases = lambda *args: True
from snakemake.utils import report

from pipelines import send_status_mail, generate_timestamp
from elmlogger import ElmLogging, ElmUnit
from bcl2fastq_dbupdate import DBUPDATE_TRIGGER_FILE_FMT, DBUPDATE_TRIGGER_FILE_MAXNUM

RESULT_OUTDIR = './out'

# ANALYSIS_ID not necessarily part of config file and if not
# needs to be passed to snakemake
assert 'ANALYSIS_ID' in config


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")


def bcl2fastq_threads_setting(num_threads):
    """Set up threads for the four bcl2fastq stages

    Illumina defaults:
    - 4 threads for reading the data:    -r, --loading-thread
    - 4 threads for writing the data:    -w, --writing-threads
    - 20% for demultiplexing data:       -d, --demultiplexing-threads
    - 100% for processing demultiplexed: -p, --processing-threads
    
    Percent here given as percent of total CPU on system which in our
    case should be the number of threads.

    Processes seem to be mutually exclusive (hard to tell though) and
    IO bound

    """

    r = min([4, num_threads])
    w = min([4, num_threads])
    d = ceil(0.2 * num_threads)
    p = ceil(1.0 * num_threads)
    return " -r {} -w {} -d {} -p {}".format(r, w, d, p)


def get_mux_dirs():
    """returns mux_dir per unit listed in config"""
    return [v['mux_dir'] for k, v in config["units"].items()]

    
def muxdir_to_url(mux_dir):
    """mux_dir has to be full path"""

    # FIXME change for testin, gis, NSCC
    if mux_dir.startswith("/mnt/projects/userrig/solexa/"):
        return mux_dir.replace("/mnt/projects/userrig/solexa/", "http://qlap33.gis.a-star.edu.sg/userrig/runs/solexaProjects/")
    else:
        raise ValueError(mux_dir)

    
def write_db_update_trigger(success):
    if success:
        status = 'SUCCESS'
    else:
        status = 'FAILED'
    update_info = {'run_num': config['run_num'],
                   'analysis_id': config['ANALYSIS_ID'],
                   'status': status}
    
    for i in range(DBUPDATE_TRIGGER_FILE_MAXNUM+1):
        dbupdate_trigger_file = DBUPDATE_TRIGGER_FILE_FMT.format(num=i)
        if not os.path.exists(dbupdate_trigger_file):
            break
    assert not os.path.exists(dbupdate_trigger_file)
    with open(dbupdate_trigger_file, 'w') as fh:
        # default_flow_style=None(default)|True(least readable)|False(most readable)
        yaml.dump(update_info, fh, default_flow_style=False)


# onstart, onsuccess and onerror are in logging.rules for analysis pipelines
# but bcl2fastq is special

onstart:# available as patched snakemake 3.5.5
    global elm_logger

    elm_units = []
    for unit in config['units'].values():
        for lane in unit['lane_ids']:
            eu = ElmUnit._make([unit['run_id'], unit['mux_id'], lane,
                                [os.path.join(RESULT_OUTDIR, unit['mux_dir'])],
                                None])
            elm_units.append(eu)
            
    elm_logger = ElmLogging(workflow.snakefile,
                            config['ELM']['pipeline_name'],
                            config['ELM']['pipeline_version'],
                            getuser(),#SET_ON_EXEC
                            config['ELM']['site'],
                            generate_timestamp(),# crutch: master jid would be best, but impossible to get here
                            config['ELM']['log_path'],#SET_ON_EXEC
                            elm_units)
    elm_logger.start()

    
onsuccess:
    elm_logger.stop(True)

    extra_text = ""
    for unit in config["units"].values():
        muxname = unit['mux_id']
        muxdir = unit['mux_dir']
        indexhtml = os.path.join(RESULT_OUTDIR, muxdir, "html/index.html")
        if os.path.exists(indexhtml):
            try:
                url = muxdir_to_url(os.path.abspath(indexhtml))
            except ValueError:
                url = "NA"
            extra_text += "Summary for {}: {}\n".format(muxname, url)
        else:
            extra_text += "Missing summary for {}: {}\n".format(muxname, url)
            
    if config.get('mail_on_completion', False):
        send_status_mail(config['ELM']['pipeline_name'], True,
                         "{} ({})".format(config['run_num'], config['ANALYSIS_ID']),
                         os.path.abspath(RESULT_OUTDIR), extra_text)
    
    # cannot talk to mongodb from compute. use trigger file
    write_db_update_trigger(True)

    
onerror:
    elm_logger.stop(False)
    if config.get('mail_on_completion', False):
        send_status_mail(config['ELM']['pipeline_name'], False,
                         "{} ({})".format(config['run_num'], config['ANALYSIS_ID']),
                         os.path.abspath(RESULT_OUTDIR))
    # cannot talk to mongodb from compute. use trigger file
    write_db_update_trigger(False)

    
rule final:
    input:
	# here, expand creates a list of expected output folders/files based on 'units'
	# defined in config (actually Project_Y/Sample_X)
        #
        # dependency per mux on bcl2fastq, so that it runs per mux
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'fastqc.SUCCESS'),
               muxdir=get_mux_dirs()),
        #expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'srasubmission.SUCCESS'),
               #muxdir=get_mux_dirs()),
        "report.html"
    message:
        """
        Pipeline run successfully completed
        """
    # Set no output in final rule. Otherwise deletion of any input will not result in a rerun


rule report:
    input:
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),

    output: html="report.html"
    run:
        # FIXME duplication with README
        report("""
        ==========================================================================================
        {config[ELM][pipeline_name]} ({config[ELM][pipeline_version]}) report for FIXME:runid
        ==========================================================================================

        FIXME:text        
        """, output.html, metadata="Research Pipeline Development Team (rpd@mailman.gis.a-star.edu.sg)", configfile="conf.yaml")
        # doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch
        # FIXME hardcoded path to configfile


def barcode_mismatch_arg_for_mux(wildcards):
    if config['units'][wildcards.muxdir]['barcode_mismatches'] is not None:
        arg = '--barcode-mismatches {}'.format(config['units'][wildcards.muxdir]['barcode_mismatches'])
    else:
        arg = ""
    return arg


rule bcl2fastq:
    """Running bcl2fastq with dynamically split threads

    https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/bcl2fastq/bcl2fastq2-v2-17-software-guide-15051736-g.pdf
    """
    input: 
        rundir = config['rundir'],
        samplesheet = config['samplesheet_csv'],
    output:
        flag = os.path.join(RESULT_OUTDIR, "{muxdir}", "bcl2fastq.SUCCESS"),
        results = os.path.join(RESULT_OUTDIR, "{muxdir}"),
    message: "Running bcl2fastq/Demultiplexing"
    threads: 16
    params:
        usebases = config['usebases_arg'],
        barcode_mismatches = barcode_mismatch_arg_for_mux,
        tiles = lambda wildcards: ''.join(["s_{},".format(lane_id) for lane_id in config['units'][wildcards.muxdir]['lane_ids']])[:-1]
    benchmark: "benchmark/bcl2fastq.txt"
    run:
        #cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        #shell(cmd)
        #shell('echo {} > {}'.format(cmd, output))
        cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --stats-dir {output.results} --reports-dir {output.results} --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        shell(cmd)
        shell("touch {output.flag}")
          
rule fastqc:
    """fastqc per muxdir. note: this will not make full use of
    parallelization of many subdirs exist simply because we don't keep
    sample information
    """
    input: '{muxdir}/bcl2fastq.SUCCESS'
    output: '{muxdir}/fastqc.SUCCESS'
    threads: 16
    message: "Running fastqc on {input}"
    benchmark: 'benchmark/fastqc.txt'
    shell:
        # note: need to be able to deal with empty directories.
        # fastqc will fail on corrupted files but return proper error code,
        # so better check input with gzip -t first
        "for f in $(find $(dirname {input}) -name \*fastq.gz); do"
        "    gzip -t $f && fastqc -t {threads} $f;"
        " done;"
        " touch {output};"





