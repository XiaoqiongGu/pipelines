import os
from math import ceil
from snakemake.utils import report
from getpass import getuser
from pipelines import send_status_mail
from elmlogger import ElmLogging, UnitId, timestamp

RESULT_OUTDIR = './out'

SAMPLESHEET = os.path.join(RESULT_OUTDIR, 'samplesheet.csv')
USEBASES_CFG = os.path.join(RESULT_OUTDIR, 'usesbases.yaml')
# ANALYSIS_ID not necessarily part of config file and if not
# needs to be passed to snakemake
assert 'ANALYSIS_ID' in config


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source snakemake_env.rc;")



def bcl2fastq_threads_setting(num_threads):
    """Set up threads for the four bcl2fastq stages

    Illumina defaults:
    - 4 threads for reading the data:    -r, --loading-thread
    - 4 threads for writing the data:    -w, --writing-threads
    - 20% for demultiplexing data:       -d, --demultiplexing-threads
    - 100% for processing demultiplexed: -p, --processing-threads
    
    Percent here given as percent of total CPU on system which in our
    case should be the number of threads.

    Processes seem to be mutually exclusive (hard to tell though) and
    IO bound

    """

    r = min([4, num_threads])
    w = min([4, num_threads])
    d = ceil(0.2 * num_threads)
    p = ceil(1.0 * num_threads)
    return " -r {} -w {} -d {} -p {}".format(r, w, d, p)


def get_mux_dirs():
    """returns mux_dir per unit listed in config"""
    return [v['mux_dir'] for k, v in config["units"].items()]

    
def testing_on():
    if 'testing' in config and config['testing']:
        return True
    else:
        return False

    
def mongodb_test_arg():
    if testing_on():
        test_arg="-t"
    else:
        test_arg = ""
    return test_arg
    
    
onstart:# available as patched snakemake 3.5.5
    global elm_logger

    if config['ELM']['run_id'] or config['ELM']['library_id'] or config['ELM']['lane_id']:
        unit_ids = [UnitId._make(x) for x in zip(
            config['ELM']['run_id'], config['ELM']['library_id'], config['ELM']['lane_id'])]
    else:
        unit_ids = [UnitId._make(['NA', 'NA', 'NA'])]
        
    elm_logger = ElmLogging(workflow.snakefile,
                            config['ELM']['pipeline_name'],
                            config['ELM']['pipeline_version'],
                            getuser(),#SET_ON_EXEC
                            config['ELM']['site'],
                            timestamp(),# crutch: master jid would be best, but site dependent. log location unknown. how to treat manual runs?
                            config['ELM']['log_path'],#SET_ON_EXEC
                            RESULT_OUTDIR,
                            unit_ids)
    elm_logger.start()

    
onsuccess:
    elm_logger.stop(True)
    shell("{} -r {} -s SUCCESS -id {} {}".format(
        config['mongo_status'], config['run_num'], config['ANALYSIS_ID'], mongodb_test_arg()))
    send_status_mail(config['ELM']['pipeline_name'], True, config['ANALYSIS_ID'], os.path.abspath(RESULT_OUTDIR)) 

    
onerror:
    elm_logger.stop(False)
    shell("{} -r {} -s FAILED -id {} {}".format(
        config['mongo_status'], config['run_num'], config['ANALYSIS_ID'], mongodb_test_arg()))
    send_status_mail(config['ELM']['pipeline_name'], False, config['ANALYSIS_ID'], os.path.abspath(RESULT_OUTDIR))

    
rule final:
    input:
	# here, expand creates a list of expected output folders/files based on 'units'
	# defined in config (actually Project_Y/Sample_X)
        #
        # dependency per mux on bcl2fastq, so that it runs per mux
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'fastqc.SUCCESS'),
               muxdir=get_mux_dirs()),
        #expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'srasubmission.SUCCESS'),
               #muxdir=get_mux_dirs()),
        "report.html"
    message:
        """
        Pipeline run successfully completed
        """
    # Set no output in final rule. Otherwise deletion of any input will not result in a rerun


rule report:
    input:
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),

    output: html="report.html"
    run:
        # FIXME duplication with README
        report("""
        ==========================================================================================
        {config[ELM][pipeline_name]} ({config[ELM][pipeline_version]}) report for FIXME:runid
        ==========================================================================================

        FIXME:text        
        """, output.html, metadata="Research Pipeline Development Team (rpd@mailman.gis.a-star.edu.sg)", configfile="conf.yaml")
        # doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch
        # FIXME hardcoded path to configfile


def barcode_mismatch_arg_for_mux(wildcards):
    if config['units'][wildcards.muxdir]['barcode_mismatches'] is not None:
        arg = '--barcode-mismatches {}'.format(config['units'][wildcards.muxdir]['barcode_mismatches'])
    else:
        arg = ""
    return ""


rule bcl2fastq:
    """Running bcl2fastq with dynamically split threads

    https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/bcl2fastq/bcl2fastq2-v2-17-software-guide-15051736-g.pdf
    """
    input: 
        rundir = config['rundir'],
        samplesheet = config['samplesheet_csv'],
    output:
        flag = os.path.join(RESULT_OUTDIR, "{muxdir}", "bcl2fastq.SUCCESS"),
        results = os.path.join(RESULT_OUTDIR, "{muxdir}"),
    message: "Running bcl2fastq/Demultiplexing"
    threads: 16
    params:
        usebases = config['usebases_arg'],
        barcode_mismatches = barcode_mismatch_arg_for_mux,
        tiles = lambda wildcards: ''.join(["s_{},".format(lane_id) for lane_id in config['units'][wildcards.muxdir]['lane_ids']])[:-1]
    benchmark: "benchmark/bcl2fastq.txt"
    run:
        #cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        #shell(cmd)
        #shell('echo {} > {}'.format(cmd, output))
        cmd = "bcl2fastq --runfolder-dir {input.rundir} --output-dir out --stats-dir {output.results} --reports-dir {output.results} --sample-sheet {input.samplesheet} {params.usebases} {params.barcode_mismatches} --tiles {params.tiles}" + bcl2fastq_threads_setting(threads)
        shell(cmd)
        shell("touch {output.flag}")
          
rule fastqc:
    """fastqc per muxdir. note: this will not make full use of
    parallelization of many subdirs exist simply because we don't keep
    sample information
    """
    input: '{muxdir}/bcl2fastq.SUCCESS'
    output: '{muxdir}/fastqc.SUCCESS'
    threads: 16
    message: "Running fastqc on {input}"
    benchmark: 'benchmark/fastqc.txt'
    shell:
        # need to be able to deal with empty directories
        # assume success and delete success flag on failure
        # fastqc will fail on corrupted files but return proper error code
        "touch {output};"
        "for f in $(find $(dirname {input}) -name \*fastq.gz); do"
        "    gzip -t $f && fastqc -t {threads} $f || rm {output};"
        "done"





