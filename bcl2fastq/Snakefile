# standard library imports
#
import os
from math import ceil
from getpass import getuser
import glob
import shutil

# third party imports
#
import yaml
# only dump() and following do not automatically create aliases
yaml.Dumper.ignore_aliases = lambda *args: True
from snakemake.utils import report

# project specific imports
#
LIB_PATH = os.path.abspath(
    os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "..", "lib"))
if LIB_PATH not in sys.path:
    sys.path.insert(0, LIB_PATH)
from pipelines import send_status_mail
from pipelines import path_to_url
from pipelines import RPD_SIGNATURE
from utils import generate_timestamp
from pipelines import mark_as_completed
from elmlogger import ElmLogging, ElmUnit
from bcl2fastq_dbupdate import DBUPDATE_TRIGGER_FILE_FMT, DBUPDATE_TRIGGER_FILE_MAXNUM
from readunits import sampledir_to_cfg, sampledir_to_cfg_2018


RESULT_OUTDIR = 'out'


# ANALYSIS_ID not necessarily part of config file and if not
# needs to be passed to snakemake
assert 'ANALYSIS_ID' in config


# non-login bash
shell.executable("/bin/bash")
shell.prefix("source rc/snakemake_env.rc;")


def bcl2fastq_threads_setting(num_threads):
    """Set up threads for the four bcl2fastq stages

    Illumina defaults:
    - 4 threads for reading the data:    -r, --loading-thread
    - 4 threads for writing the data:    -w, --writing-threads
    - 20% for demultiplexing data:       -d, --demultiplexing-threads
    - 100% for processing demultiplexed: -p, --processing-threads
    
    Percent here given as percent of total CPU on system which in our
    case should be the number of threads.

    Processes seem to be mutually exclusive (hard to tell though) and
    IO bound
    """

    r = min([4, num_threads])
    w = min([4, num_threads])
    p = ceil(1.0 * num_threads)
    return "-r {} -w {} -p {}".format(r, w, p)


def get_mux_dirs():
    """returns mux_dir per unit listed in config"""
    return [v['mux_dir'] for k, v in config["units"].items()]

    
    
def write_db_update_trigger(success):
    if success:
        status = 'SUCCESS'
    else:
        status = 'FAILED'
    update_info = {'run_num': config['run_num'],
                   'analysis_id': config['ANALYSIS_ID'],
                   'status': status}
    
    for i in range(DBUPDATE_TRIGGER_FILE_MAXNUM+1):
        dbupdate_trigger_file = DBUPDATE_TRIGGER_FILE_FMT.format(num=i)
        if not os.path.exists(dbupdate_trigger_file):
            break
    assert not os.path.exists(dbupdate_trigger_file)
    with open(dbupdate_trigger_file, 'w') as fh:
        # default_flow_style=None(default)|True(least readable)|False(most readable)
        yaml.dump(update_info, fh, default_flow_style=False)


def barcode_mismatch_arg_for_mux(wildcards):
    if config['units'][wildcards.muxdir]['barcode_mismatches'] is not None:
        arg = '--barcode-mismatches {}'.format(config['units'][wildcards.muxdir]['barcode_mismatches'])
    else:
        arg = ""
    return arg


# NOTE: onstart, onsuccess and onerror are normally in logging.rules
# for analysis pipelines but bcl2fastq needs special versions
onstart:
    global elm_logger

    elm_units = []
    for unit in config['units'].values():
        for lane in unit['lane_ids']:
            eu = ElmUnit._make([unit['run_id'], unit['mux_id'], lane,
                                [os.path.join(RESULT_OUTDIR, unit['mux_dir'])],
                                None])
            elm_units.append(eu)
            
    elm_logger = ElmLogging(workflow.snakefile,
                            config['ELM']['pipeline_name'],
                            config['ELM']['pipeline_version'],
                            getuser(),#SET_ON_EXEC
                            config['ELM']['site'],
                            generate_timestamp(),# crutch: master jid would be best, but impossible to get here
                            config['ELM']['log_path'],#SET_ON_EXEC
                            elm_units)
    elm_logger.start()

    
# NOTE: onstart, onsuccess and onerror are normally in logging.rules
# for analysis pipelines but bcl2fastq needs special versions
onsuccess:
    elm_logger.stop(True)

    extra_text = ""
    for unit in config["units"].values():
        muxname = unit['mux_id']
        muxdir = unit['mux_dir']
        indexhtml = os.path.abspath(os.path.join(
            RESULT_OUTDIR, muxdir, "html/index.html"))
        if os.path.exists(indexhtml):
            try:
                # only works when in production output directory
                url = path_to_url(indexhtml)
            except ValueError:
                # otherwise just report the file path
                url = "file://{}".format(indexhtml)
        else:
            # if missing something's wrong
            url = "ERROR:MISSING"
        extra_text += "Summary for {}: {}\n".format(muxname, url)

    if config.get('mail_on_completion', False):
        send_status_mail(config['ELM']['pipeline_name'], True,
                         "{} ({})".format(config['run_num'], config['ANALYSIS_ID']),
                         os.path.abspath(RESULT_OUTDIR), extra_text=extra_text)
    # cannot talk to mongodb from compute. use trigger file
    write_db_update_trigger(True)
    
    mark_as_completed()

    
onerror:
    elm_logger.stop(False)
    if config.get('mail_on_completion', False):
        send_status_mail(config['ELM']['pipeline_name'], False,
                         "{} ({})".format(config['run_num'], config['ANALYSIS_ID']),
                         os.path.abspath(RESULT_OUTDIR))
    # cannot talk to mongodb from compute. use trigger file
    write_db_update_trigger(False)


localrules: final, report


rule final:
    input:
	# here, expand creates a list of expected output folders/files based on 'units'
	# defined in config (actually Project_Y/Sample_X)
        #
        # dependency per mux on bcl2fastq, so that it runs per mux
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'bcl2fastq.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'fastqc.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'drop_index_note.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'create_sample_configs.SUCCESS'),
               muxdir=get_mux_dirs()),
        expand(os.path.join(RESULT_OUTDIR, '{muxdir}', 'multiqc.html'),
               muxdir=get_mux_dirs()),
        report="report.html"
    message:
        """
        Pipeline run successfully completed
        """
    # Set no output in final rule. Otherwise deletion of any input will not result in a rerun


# FIXME almost identical to rules/report.rules but with different analysis_name
rule report:
    input:
        readme = os.path.join(os.path.dirname(os.path.realpath(workflow.snakefile)), "README.md"),
        conf = "conf.yaml",
    output:
        html="report.html"
    params:
        analysis_name = config.get('analysis_name', config['run_num'])
    run:
        report("""
=================================================================
Pipeline {config[ELM][pipeline_name]} run on {params.analysis_name}
=================================================================


- The used pipeline version was {config[ELM][pipeline_version]}
- Parameters including program versions etc. can be found in the attached conf_ file
- Output files can be found in ``./out/``
- The main log file is `./logs/snakemake.log`
- See {input.readme} for a description of this pipeline
""",
               output.html,
               conf=input.conf,
               metadata="Research Pipeline Development Team (rpd@gis.a-star.edu.sg)",
               )
        # from doc "All keywords not listed below are intepreted as paths to files that shall be embedded into the document."
        # **input just attaches all input, but None is not allowed.
        # Attaching configfile is more a crutch to have at least something



rule bcl2fastq:
    """Running bcl2fastq with dynamically split threads

    https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/bcl2fastq/bcl2fastq2-v2-17-software-guide-15051736-g.pdf
    """
    input: 
        samplesheet = lambda wildcards: config['units'][wildcards.muxdir]['samplesheet']
    output:
        flag = os.path.join(RESULT_OUTDIR, "{muxdir}", "bcl2fastq.SUCCESS")
    log:
        os.path.join(RESULT_OUTDIR, "{muxdir}.log")
    benchmark:
        os.path.join(RESULT_OUTDIR, "{muxdir}", "bcl2fastq.benchmark.log")
    message:
        "Running bcl2fastq/Demultiplexing"
    threads:
        12
    params:
        bcl2fastq_custom_args = lambda wildcards: ''.join(["{}".format(bcl2fastq_custom_args) for bcl2fastq_custom_args in config['units'][wildcards.muxdir]['bcl2fastq_custom_args']]),
        barcode_mismatches = barcode_mismatch_arg_for_mux,
        tiles = lambda wildcards: ''.join(["s_{},".format(lane_id) for lane_id in config['units'][wildcards.muxdir]['lane_ids']])[:-1],
        tool = lambda wildcards: config['units'][wildcards.muxdir]['tool'],
        mux_id = lambda wildcards: config['units'][wildcards.muxdir]['mux_id'],
        mux_dir = lambda wildcards: config['units'][wildcards.muxdir]['mux_dir']
    run:
        if params.tool == "bcl2fastq":
            res_dir = os.path.dirname(output.flag)
            cmd = "bcl2fastq --runfolder-dir {config[rundir]} --output-dir %s" % RESULT_OUTDIR
            cmd += " --stats-dir %s --reports-dir %s" % (res_dir, res_dir)
            cmd += " {}".format(params.bcl2fastq_custom_args)
            cmd += " --sample-sheet {input.samplesheet}"
            cmd += " {params.barcode_mismatches} --tiles {params.tiles}"
            cmd += " %s" % bcl2fastq_threads_setting(threads)
            cmd += " >& {log}"
            shell(cmd)
            shell("touch {output.flag}")
        elif params.tool == "10xGenomics":
            samplesheet = os.path.abspath(input.samplesheet)
            tmp_workdir = "{params.mux_id}.cellranger.tmp"
            log = os.path.abspath("%s") % log
            res_dir = os.path.abspath(os.path.dirname(output.flag))
            if os.path.exists(tmp_workdir):
                shutil.rmtree(tmp_workdir)
            assert os.path.isabs(config['rundir'])
            cmd = "mkdir -p %s;" % tmp_workdir
            cmd += "cd %s;" % tmp_workdir
            cmd += " cellranger mkfastq --run={config[rundir]} --output-dir=out"
            cmd += " --samplesheet=%s --ignore-dual-index " % samplesheet
            cmd += " --stats-dir %s --reports-dir %s" % (res_dir, res_dir)
            cmd += " {}".format(params.bcl2fastq_custom_args)
            cmd += " {params.barcode_mismatches} --tiles {params.tiles}"
            cmd += " %s" % bcl2fastq_threads_setting(threads)
            cmd += " >& %s;" % log
            dest_mux_dir = os.path.abspath(os.path.join(RESULT_OUTDIR, '{params.mux_dir}'))
            tmp_sample_dir = tmp_workdir + "/out/Project*/*"
            #Move data into out folder
            cmd += " mv -i %s %s;" % (os.path.abspath(tmp_sample_dir), dest_mux_dir)
            if '{params.mux_dir}'.startswith('MUX'):
                cmd += " cp -rpi %s/out/Undetermined* %s;" % (os.path.abspath(tmp_workdir), os.path.abspath(os.path.join(RESULT_OUTDIR)))
            shell(cmd)
            shell("touch {output.flag}")

            
rule fastqc:
    """fastqc per muxdir. note: this will not make full use of
    parallelization of many subdirs exist simply because we don't keep
    sample information
    """
    input: 
        '{muxdir}/bcl2fastq.SUCCESS'
    output:
        touch('{muxdir}/fastqc.SUCCESS')
    log:
        '{muxdir}/fastqc.log'
    benchmark:
        "{muxdir}/fastqc.benchmark.log"
    threads:
        8
    message:
        "Running fastqc on {input}"
    shell:
        # note: need to be able to deal with empty directories.
        # fastqc will fail on corrupted files but return proper error code,
        # so better check input with gzip -t first.
	# rarely saw fastqc threads actually get more than 100% so no point in using threading option
        "{{"
        " find $(dirname {input}) -name \*fastq.gz | xargs --no-run-if-empty -n 1 -P {threads} gzip -t;"
        " find $(dirname {input}) -name \*fastq.gz | xargs --no-run-if-empty -n 1 -P {threads} fastqc;"
        " }} >& {log}"

        
localrules: drop_index_note
rule drop_index_note:
    """drop a note per index file pointing out that they are...index files.
    """
    input: 
        '{muxdir}/bcl2fastq.SUCCESS'
    output:
        touch('{muxdir}/drop_index_note.SUCCESS')
    log:
        '{muxdir}/drop_index_note.log'
    threads:
        1
    message:
        "Running fastqc on {input}"
    run:
        # note: need to be able to deal with empty directories.
        for ifq in glob.glob(os.path.join(os.path.dirname(str(input[0])), "*", "*_I[12]_*fastq.gz")):
            with open(ifq + ".README", 'w') as fh:
                fh.write("The _I1_ and _I2_ fastq files are index files.\n")
                fh.write("Use them only if you know exactly what you are doing.\n")
                fh.write("Most users will only be interested in the _R1_ and _R2_ fastq files\n")
                fh.write("\n{}\n".format(RPD_SIGNATURE))
    

localrules: multiqc
rule multiqc:
    """Create sample configs (sample.yaml) per sample dir
    """
    input: 
        '{muxdir}/fastqc.SUCCESS'
    output:
        reporthtml = '{muxdir}/multiqc.html',
        datazip  = '{muxdir}/multiqc_data.zip'
    threads:
        1
    log:
        '{muxdir}/multiqc.log'
    message:
        "Running MultiQC"
    params:
        mux_id = lambda wildcards: os.path.split(wildcards.muxdir)[-1],
        prefix = lambda wildcards: os.path.join(wildcards.muxdir, "multiqc")
    shell:
        # --outdir is where all output will be stored
        # --filename is actually the basename prefix
        # note: cellranger comes with its own python and conda and doesn't play nicely with multiqc
        # so we have to load this locally
        # LANG needs to be set because of problems with click. See http://click.pocoo.org/5/python3/
        """{{
        export LC_ALL=en_GB.utf8;
        export LANG=en_GB.utf8;
        module load multiqc/1.5a;
        multiqc -v --title {params.mux_id} --outdir $(dirname {input}) \
          -f --export --filename multiqc \
          --zip-data-dir -m fastqc --ignore-samples '*_I[12]_*' $(dirname {input}); }} >& {log};
        """
        
                    
localrules: create_sample_configs
rule create_sample_configs:
    """Create sample configs (sample.yaml) per sample dir
    """
    input: 
        '{muxdir}/bcl2fastq.SUCCESS'
    output:
        touch('{muxdir}/create_sample_configs.SUCCESS')
    threads:
        1
    message:
        "Creating sample configs"
    run:
        for mux_key, mux_unit in config['units'].items():
            mux_dir = os.path.join(RESULT_OUTDIR, mux_unit['mux_dir'])
            run_id = mux_unit['run_id']
            flowcell_id = mux_unit['flowcell_id']
            for sample_dir in glob.glob(os.path.join(mux_dir, "Sample_*")):
                sample_cfgfile = os.path.abspath(os.path.join(sample_dir, "sample.yaml"))
                if not os.path.exists(sample_cfgfile):
                    # make sure to skip dirs with no fastq files
                    sampledir_to_cfg(sample_dir, sample_cfgfile,
                                     run_id=run_id, flowcell_id=flowcell_id, fail_if_no_matches=False)
            # sample config generation for newer nfcore pipelines
            for sample_dir in glob.glob(os.path.join(mux_dir, "Sample_*")):
                sample_cfgfile_2018 = os.path.abspath(os.path.join(sample_dir, "sample_2018.yaml"))
                if not os.path.exists(sample_cfgfile_2018):
                    # make sure to skip dirs with no fastq files
                    sampledir_to_cfg_2018(sample_dir, sample_cfgfile_2018,
                                     run_id=run_id, flowcell_id=flowcell_id, fail_if_no_matches=False)
